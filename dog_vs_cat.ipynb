{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'input/train/'\n",
    "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]\n",
    "train_dogs = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "train_cats = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images_partial = train_dogs[:100] +train_cats[:100]\n",
    "random.shuffle(train_images_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature = []\n",
    "for img in train_images_partial:\n",
    "    img = cv2.imread(img)\n",
    "    img = cv2.resize(img, dsize=(64,64))\n",
    "    feature.append(img)\n",
    "feature=np.array(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label = ['cat' if 'cat' in i else 'dog' for i in train_images_partial]\n",
    "label=[[0, 1] if i=='cat' else [1, 0] for i in label]\n",
    "label=np.int32(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature=np.int32(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature = (feature-np.min(feature))/(np.max(feature)-np.min(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEMdJREFUeJzt3X+s3XV9x/Hna+3E+oNfctOwlqxNbNxK3ebosNO4ELuE\nLqLlDyU101bXwQzMqXExdP6BWdIEo5kb28B0w1GcEyqT0G2yycrEmVjYBVQoWGmsSDugF0XwR8QV\n3/vjfhoP91O4cM9tz8U+H8nJ+Zz39/P5nvcJnLzy/XFuU1VIkjToF0bdgCRp7jEcJEkdw0GS1DEc\nJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1Jk/6gZm6pRTTqklS5aMug1Jel65/fbbH6mqsenmPW/D\nYcmSJYyPj4+6DUl6Xkly/7OZ52klSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwH\nSVLnefsL6WEsufjfRt3CnPWtS98w6hYkwO/pMzka31OPHCRJHcNBktQxHCRJnWnDIcknkhxIcvdA\n7SNJvp7ka0muT3LiwLZNSfYk2Z3k7IH6GUnuatsuS5JWPy7Jta1+a5Ils/sRJUnP1bM5crgKWDOl\ndhOwoqp+DfgGsAkgyXJgHXB6W3N5knltzRXA+cCy9ji0z43Ao1X1cuBjwIdn+mEkSbNj2nCoqi8C\n351S+3xVHWwvdwKL23gtcE1VPVFVe4E9wJlJTgWOr6qdVVXA1cC5A2u2tvF1wOpDRxWSpNGYjWsO\nfwDc2MaLgAcGtu1rtUVtPLX+lDUtcB4DXjYLfUmSZmiocEjyQeAg8KnZaWfa97sgyXiS8YmJiaPx\nlpJ0TJpxOCR5B3AO8PvtVBHAfuC0gWmLW20/Pzv1NFh/ypok84ETgO8c7j2raktVrayqlWNj0/4T\nqJKkGZpROCRZA3wAeFNV/Whg03ZgXbsDaSmTF55vq6oHgceTrGrXE9YDNwys2dDGbwZuHggbSdII\nTPvnM5J8GjgLOCXJPuASJu9OOg64qV073llV76qqXUm2Afcwebrpoqp6su3qQibvfFrA5DWKQ9cp\nrgQ+mWQPkxe+183OR5MkzdS04VBVbz1M+cpnmL8Z2HyY+jiw4jD1HwNvma4PSdLR4y+kJUkdw0GS\n1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEc\nJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1Jk2HJJ8IsmBJHcP1E5O\nclOS+9rzSQPbNiXZk2R3krMH6mckuattuyxJWv24JNe2+q1JlszuR5QkPVfP5sjhKmDNlNrFwI6q\nWgbsaK9JshxYB5ze1lyeZF5bcwVwPrCsPQ7tcyPwaFW9HPgY8OGZfhhJ0uyYNhyq6ovAd6eU1wJb\n23grcO5A/ZqqeqKq9gJ7gDOTnAocX1U7q6qAq6esObSv64DVh44qJEmjMdNrDgur6sE2fghY2MaL\ngAcG5u1rtUVtPLX+lDVVdRB4DHjZDPuSJM2CoS9ItyOBmoVeppXkgiTjScYnJiaOxltK0jFppuHw\ncDtVRHs+0Or7gdMG5i1utf1tPLX+lDVJ5gMnAN853JtW1ZaqWllVK8fGxmbYuiRpOjMNh+3Ahjbe\nANwwUF/X7kBayuSF59vaKajHk6xq1xPWT1lzaF9vBm5uRyOSpBGZP92EJJ8GzgJOSbIPuAS4FNiW\nZCNwP3AeQFXtSrINuAc4CFxUVU+2XV3I5J1PC4Ab2wPgSuCTSfYweeF73ax8MknSjE0bDlX11qfZ\ntPpp5m8GNh+mPg6sOEz9x8BbputDknT0+AtpSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLH\ncJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAk\ndQwHSVLHcJAkdQwHSVLHcJAkdQwHSVJnqHBI8r4ku5LcneTTSV6Y5OQkNyW5rz2fNDB/U5I9SXYn\nOXugfkaSu9q2y5JkmL4kScOZcTgkWQT8CbCyqlYA84B1wMXAjqpaBuxor0myvG0/HVgDXJ5kXtvd\nFcD5wLL2WDPTviRJwxv2tNJ8YEGS+cCLgP8F1gJb2/atwLltvBa4pqqeqKq9wB7gzCSnAsdX1c6q\nKuDqgTWSpBGYcThU1X7go8C3gQeBx6rq88DCqnqwTXsIWNjGi4AHBnaxr9UWtfHUeifJBUnGk4xP\nTEzMtHVJ0jSGOa10EpNHA0uBXwJenORtg3PakUAN1eFT97elqlZW1cqxsbHZ2q0kaYphTiv9LrC3\nqiaq6v+AzwKvAR5up4pozwfa/P3AaQPrF7fa/jaeWpckjcgw4fBtYFWSF7W7i1YD9wLbgQ1tzgbg\nhjbeDqxLclySpUxeeL6tnYJ6PMmqtp/1A2skSSMwf6YLq+rWJNcBdwAHgTuBLcBLgG1JNgL3A+e1\n+buSbAPuafMvqqon2+4uBK4CFgA3tockaURmHA4AVXUJcMmU8hNMHkUcbv5mYPNh6uPAimF6kSTN\nHn8hLUnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7h\nIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpM5Q4ZDk\nxCTXJfl6knuT/HaSk5PclOS+9nzSwPxNSfYk2Z3k7IH6GUnuatsuS5Jh+pIkDWfYI4e/Av69qn4F\n+HXgXuBiYEdVLQN2tNckWQ6sA04H1gCXJ5nX9nMFcD6wrD3WDNmXJGkIMw6HJCcAvwNcCVBVP6mq\n7wFrga1t2lbg3DZeC1xTVU9U1V5gD3BmklOB46tqZ1UVcPXAGknSCAxz5LAUmAD+IcmdSf4+yYuB\nhVX1YJvzELCwjRcBDwys39dqi9p4ar2T5IIk40nGJyYmhmhdkvRMhgmH+cBvAldU1auAH9JOIR3S\njgRqiPd4iqraUlUrq2rl2NjYbO1WkjTFMOGwD9hXVbe219cxGRYPt1NFtOcDbft+4LSB9YtbbX8b\nT61LkkZkxuFQVQ8BDyR5RSutBu4BtgMbWm0DcEMbbwfWJTkuyVImLzzf1k5BPZ5kVbtLaf3AGknS\nCMwfcv27gU8leQHwTeCdTAbOtiQbgfuB8wCqaleSbUwGyEHgoqp6su3nQuAqYAFwY3tIkkZkqHCo\nqq8AKw+zafXTzN8MbD5MfRxYMUwvkqTZ4y+kJUkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkd\nw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS\n1DEcJEkdw0GS1DEcJEkdw0GS1Bk6HJLMS3Jnkn9tr09OclOS+9rzSQNzNyXZk2R3krMH6mckuatt\nuyxJhu1LkjRzs3Hk8B7g3oHXFwM7qmoZsKO9JslyYB1wOrAGuDzJvLbmCuB8YFl7rJmFviRJMzRU\nOCRZDLwB+PuB8lpgaxtvBc4dqF9TVU9U1V5gD3BmklOB46tqZ1UVcPXAGknSCAx75PCXwAeAnw7U\nFlbVg238ELCwjRcBDwzM29dqi9p4al2SNCIzDock5wAHqur2p5vTjgRqpu9xmPe8IMl4kvGJiYnZ\n2q0kaYphjhxeC7wpybeAa4DXJ/lH4OF2qoj2fKDN3w+cNrB+cavtb+Op9U5VbamqlVW1cmxsbIjW\nJUnPZMbhUFWbqmpxVS1h8kLzzVX1NmA7sKFN2wDc0MbbgXVJjkuylMkLz7e1U1CPJ1nV7lJaP7BG\nkjQC84/APi8FtiXZCNwPnAdQVbuSbAPuAQ4CF1XVk23NhcBVwALgxvaQJI3IrIRDVX0B+EIbfwdY\n/TTzNgObD1MfB1bMRi+SpOH5C2lJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJ\nUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdw\nkCR1DAdJUsdwkCR1ZhwOSU5L8l9J7kmyK8l7Wv3kJDclua89nzSwZlOSPUl2Jzl7oH5GkrvatsuS\nZLiPJUkaxjBHDgeB91fVcmAVcFGS5cDFwI6qWgbsaK9p29YBpwNrgMuTzGv7ugI4H1jWHmuG6EuS\nNKQZh0NVPVhVd7Tx94F7gUXAWmBrm7YVOLeN1wLXVNUTVbUX2AOcmeRU4Piq2llVBVw9sEaSNAKz\ncs0hyRLgVcCtwMKqerBteghY2MaLgAcGlu1rtUVtPLUuSRqRocMhyUuAfwbeW1WPD25rRwI17HsM\nvNcFScaTjE9MTMzWbiVJUwwVDkl+kclg+FRVfbaVH26nimjPB1p9P3DawPLFrba/jafWO1W1papW\nVtXKsbGxYVqXJD2DYe5WCnAlcG9V/cXApu3AhjbeANwwUF+X5LgkS5m88HxbOwX1eJJVbZ/rB9ZI\nkkZg/hBrXwu8HbgryVda7c+AS4FtSTYC9wPnAVTVriTbgHuYvNPpoqp6sq27ELgKWADc2B6SpBGZ\ncThU1ZeAp/s9wuqnWbMZ2HyY+jiwYqa9SJJml7+QliR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdw\nkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1DAdJUsdwkCR1\nDAdJUsdwkCR1DAdJUsdwkCR1DAdJUmfOhEOSNUl2J9mT5OJR9yNJx7I5EQ5J5gF/C/wesBx4a5Ll\no+1Kko5dcyIcgDOBPVX1zar6CXANsHbEPUnSMWuuhMMi4IGB1/taTZI0AvNH3cBzkeQC4IL28gdJ\ndo+yn1lyCvDIqJs4JB8edQfSnDVnvqtDfk9/+dlMmivhsB84beD14lZ7iqraAmw5Wk0dDUnGq2rl\nqPuQ9MyOte/qXDmt9D/AsiRLk7wAWAdsH3FPknTMmhNHDlV1MMkfA/8BzAM+UVW7RtyWJB2z5kQ4\nAFTV54DPjbqPEfi5Ok0m/Rw7pr6rqapR9yBJmmPmyjUHSdIcYjgcZUk+lORPR92HpJlLclaS14y6\njyPJcJCk5+4swHDQcJJ8MMk3knwJeEWr/UaSnUm+luT6JCe1+m+12leSfCTJ3SNtXjqGJFnfvn9f\nTfLJJG9McmuSO5P8Z5KFSZYA7wLe176nrxtt10eGF6SPsCRnAFcBr2by7rA7gI8D64F3V9UtSf4c\nOL6q3tvC4Pyq+nKSS4FzqmrFiNqXjhlJTgeuB15TVY8kORko4HtVVUn+EPjVqnp/kg8BP6iqj46w\n5SNqztzK+nPsdcD1VfUjgCTbgRcDJ1bVLW3OVuAzSU4EXlpVX271fwLOOdoNS8eo1wOfqapHAKrq\nu0leCVyb5FTgBcDeUTZ4NHlaSZKe3l8Df1NVrwT+CHjhiPs5agyHI++LwLlJFiR5KfBG4IfAowPn\nKt8O3FJV3wO+n+TVrb7u6LcrHbNuBt6S5GUA7bTSCfzs77xtGJj7feClR7e9o8vTSkdYVd2R5Frg\nq8ABJv+OFEz+j/bxJC8Cvgm8s9U3An+X5KfALcBjR7ll6ZhUVbuSbAZuSfIkcCfwISZP+T7KZHgs\nbdP/BbguyVomrx3+9yh6PpK8ID3HJHlJVf2gjS8GTq2q94y4LUnHGI8c5p43JNnE5H+b+4F3jLYd\nSccijxwkSR0vSEuSOoaDJKljOEiSOoaDJKljOEiSOoaDJKnz/1umcJnWH1k2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a0d0418be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([1,2], [len(train_dogs), len(train_cats)], width=0.3)\n",
    "plt.xticks([1,2],['dog', 'cat'])\n",
    "plt.savefig('dogvscat.jpg',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return tf.placeholder(tf.float32, shape=(None, image_shape[0], image_shape[1], image_shape[2]), name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=(None, n_classes), name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight =  tf.Variable(tf.random_normal(conv_ksize+(x_tensor.shape[-1].value,)+(conv_num_outputs,),\n",
    "                                           stddev=0.05))\n",
    "    bias = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    x = tf.nn.conv2d(x_tensor, weight, strides=(1,)+conv_strides+(1,), padding='SAME')\n",
    "    x = tf.nn.bias_add(x, bias)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.nn.max_pool(x, ksize=((1,)+ pool_ksize + (1,)),\n",
    "                      strides=((1,)+ pool_strides + (1,)),\n",
    "                      padding='SAME')\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    flatten_x = tf.reshape(x_tensor, \n",
    "                           shape=[tf.shape(x_tensor)[0], x_tensor.shape[1].value*x_tensor.shape[2].value*x_tensor.shape[3].value])\n",
    "    return flatten_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.truncated_normal((x_tensor.shape[-1].value, num_outputs),\n",
    "                                            stddev = 0.05))\n",
    "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "    fc_x = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    fc_x = tf.nn.relu(fc_x)\n",
    "    \n",
    "    return fc_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.truncated_normal([x_tensor.shape[-1].value,num_outputs],\n",
    "                                            stddev=0.05))\n",
    "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "    return tf.add(tf.matmul(x_tensor, weight), bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv = conv2d_maxpool(x, 32, (4,4), (1,1), (3,3), (2,2))\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flt = flatten(conv)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fc = fully_conn(flt, 512)\n",
    "    fc = tf.nn.dropout(fc, keep_prob)\n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return output(fc, 2)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((64, 64, 3))\n",
    "y = neural_net_label_input(2)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={\n",
    "            x: feature_batch,\n",
    "            y: label_batch,\n",
    "            keep_prob: keep_probability\n",
    "        })\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={\n",
    "            x: feature_batch,\n",
    "            y: label_batch,\n",
    "            keep_prob: 1.\n",
    "        })\n",
    "    global valid_features, valid_labels\n",
    "    valid_acc = session.run(accuracy, feed_dict={\n",
    "            x: feature,\n",
    "            y: label,\n",
    "            keep_prob: 1.\n",
    "        })\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 12\n",
    "batch_size = 8\n",
    "keep_probability = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        train_neural_network(sess, optimizer, keep_probability, feature, label)\n",
    "        #print_stats(sess, feature, label, cost, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dlnd-tf-lab]",
   "language": "python",
   "name": "conda-env-dlnd-tf-lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

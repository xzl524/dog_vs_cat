{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If come back to this notebook or have to restart the notebook, start from Check Point. The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'input/train/'\n",
    "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset\n",
    "image_id = 10000\n",
    "\n",
    "# Don't modify below\n",
    "image_example = cv2.imread(train_images[image_id])\n",
    "print(\"Stats of Dog_vs_Cat Training Dataset\")\n",
    "print(\"Total Images: {}\".format(len(train_images)))\n",
    "print(\"Dog:          {}\".format(len([i for i in train_images if 'dog' in i ])))\n",
    "print(\"Cat:          {}\".format(len([i for i in train_images if 'cat' in i ])))\n",
    "print(\"\")\n",
    "print(\"Example of Image {}\".format(image_id))\n",
    "print(\"Image - Shape: {}\".format(image_example.shape))\n",
    "print(\"Image - Min Value: {}, Max Value: {}\".format(image_example.min(), image_example.max()))\n",
    "print(\"Label - {}\".format('dog' if 'dog' in train_images[image_id] else 'cat'))\n",
    "display(Image.open(train_images[image_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomize Data\n",
    "random.shuffle(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images\n",
    "ROWS = 64 #Resized image row size\n",
    "COLS = 64 #Resized image columns size\n",
    "CHANNELS = 3 #RGB channels\n",
    "\n",
    "# Don't modify below\n",
    "feature = []\n",
    "for i, img in enumerate(train_images): \n",
    "    img = cv2.imread(img)\n",
    "    img = cv2.resize(img, dsize=(ROWS, COLS))\n",
    "    feature.append(img)\n",
    "feature = np.array(feature, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the resized image\n",
    "image_example_new = 10\n",
    "\n",
    "#Don't modify below\n",
    "print('Resized Image')\n",
    "display(Image.fromarray(feature[image_example_new]))\n",
    "print('')\n",
    "print('Original Image')\n",
    "display(Image.open(train_images[image_example_new]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "feature = (feature-np.min(feature))/(np.max(feature)-np.min(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encoding on the label\n",
    "label = [[0, 1] if 'cat' in i else [1, 0] for i in train_images]\n",
    "label = np.array(label, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('preprocess_image.p', 'wb') as f:\n",
    "    pickle.dump((feature,label), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If come back to this notebook or have to restart the notebook, start from here. The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocess_image.p', 'rb') as f:\n",
    "    feature, label = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image - Shape: (64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Image - Shape: {}\".format(feature.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zaoli\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train test split to generate training set and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "training_size = 0.9 # 90% of the data will be used as training, \n",
    "                    #and the remaining 10% will be used as validation set\n",
    "train_feature, val_feature, train_label, val_label=train_test_split(feature, label, train_size=training_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    weight =  tf.Variable(tf.random_normal(conv_ksize+(x_tensor.shape[-1].value,)+(conv_num_outputs,),\n",
    "                                           stddev=0.05))\n",
    "    bias = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    x = tf.nn.conv2d(x_tensor, weight, strides=(1,)+conv_strides+(1,), padding='SAME')\n",
    "    x = tf.nn.bias_add(x, bias)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.nn.max_pool(x, ksize=((1,)+ pool_ksize + (1,)),\n",
    "                      strides=((1,)+ pool_strides + (1,)),\n",
    "                      padding='SAME')\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    flatten_x = tf.reshape(x_tensor, \n",
    "                           shape=[tf.shape(x_tensor)[0], x_tensor.shape[1].value*x_tensor.shape[2].value*x_tensor.shape[3].value])\n",
    "    return flatten_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    weight = tf.Variable(tf.truncated_normal((x_tensor.shape[-1].value, num_outputs),\n",
    "                                            stddev = 0.05))\n",
    "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "    fc_x = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    fc_x = tf.nn.relu(fc_x)\n",
    "    \n",
    "    return fc_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight = tf.Variable(tf.truncated_normal([x_tensor.shape[-1].value,num_outputs],\n",
    "                                            stddev=0.05))\n",
    "    bias = tf.Variable(tf.zeros([num_outputs]))\n",
    "    return tf.add(tf.matmul(x_tensor, weight), bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv = conv2d_maxpool(x, 32, (4,4), (1,1), (3,3), (2,2))\n",
    "\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flt = flatten(conv)\n",
    "\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fc = fully_conn(flt, 512)\n",
    "    fc = tf.nn.dropout(fc, keep_prob)\n",
    "\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return output(fc, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "ROWS = feature.shape[1]\n",
    "COLS = feature.shape[2] #Resized image columns size\n",
    "CHANNELS = feature.shape[3] #RGB channels\n",
    "image_shape = (ROWS, COLS, CHANNELS)\n",
    "n_classes = label.shape[1]\n",
    "x = tf.placeholder(tf.float32, shape = (None, image_shape[0], image_shape[1], image_shape[2]), name='x')\n",
    "y = tf.placeholder(tf.float32, shape = (None, n_classes), name='y')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y), name='cost')\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Parameters\n",
    "epochs = 12\n",
    "batch_size = 256\n",
    "keep_probability = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, Batch 1: \n",
      "Training Loss: 13.3315, Validation Loss: 14.6200, Validation Accuracy: 50.44%\n",
      "Epoch  1, Batch 2: \n",
      "Training Loss: 4.5915, Validation Loss: 4.3737, Validation Accuracy: 50.44%\n",
      "Epoch  1, Batch 3: \n",
      "Training Loss: 2.2623, Validation Loss: 2.2462, Validation Accuracy: 49.56%\n",
      "Epoch  1, Batch 4: \n",
      "Training Loss: 2.5073, Validation Loss: 2.5780, Validation Accuracy: 49.56%\n",
      "Epoch  1, Batch 5: \n",
      "Training Loss: 1.9971, Validation Loss: 2.0622, Validation Accuracy: 49.56%\n",
      "Epoch  1, Batch 6: \n",
      "Training Loss: 1.3078, Validation Loss: 1.3892, Validation Accuracy: 49.56%\n",
      "Epoch  1, Batch 7: \n",
      "Training Loss: 0.8735, Validation Loss: 0.8919, Validation Accuracy: 49.56%\n",
      "Epoch  1, Batch 8: \n",
      "Training Loss: 0.7030, Validation Loss: 0.7096, Validation Accuracy: 43.24%\n",
      "Epoch  1, Batch 9: \n",
      "Training Loss: 0.7395, Validation Loss: 0.7476, Validation Accuracy: 50.32%\n",
      "Epoch  1, Batch 10: \n",
      "Training Loss: 0.7631, Validation Loss: 0.8006, Validation Accuracy: 50.44%\n",
      "Epoch  1, Batch 11: \n",
      "Training Loss: 0.7766, Validation Loss: 0.8038, Validation Accuracy: 50.44%\n",
      "Epoch  1, Batch 12: \n",
      "Training Loss: 0.7829, Validation Loss: 0.7767, Validation Accuracy: 50.44%\n",
      "Epoch  1, Batch 13: \n",
      "Training Loss: 0.7446, Validation Loss: 0.7432, Validation Accuracy: 50.44%\n",
      "Epoch  1, Batch 14: \n",
      "Training Loss: 0.7320, Validation Loss: 0.7133, Validation Accuracy: 50.44%\n",
      "Epoch  1, Batch 15: \n",
      "Training Loss: 0.6871, Validation Loss: 0.6957, Validation Accuracy: 50.40%\n",
      "Epoch  1, Batch 16: \n",
      "Training Loss: 0.6853, Validation Loss: 0.6903, Validation Accuracy: 51.40%\n",
      "Epoch  1, Batch 17: \n",
      "Training Loss: 0.6931, Validation Loss: 0.6917, Validation Accuracy: 53.56%\n",
      "Epoch  1, Batch 18: \n",
      "Training Loss: 0.6914, Validation Loss: 0.6941, Validation Accuracy: 50.20%\n",
      "Epoch  1, Batch 19: \n",
      "Training Loss: 0.6958, Validation Loss: 0.6953, Validation Accuracy: 49.96%\n",
      "Epoch  1, Batch 20: \n",
      "Training Loss: 0.6915, Validation Loss: 0.6957, Validation Accuracy: 49.80%\n",
      "Epoch  1, Batch 21: \n",
      "Training Loss: 0.6949, Validation Loss: 0.6946, Validation Accuracy: 49.76%\n",
      "Epoch  1, Batch 22: \n",
      "Training Loss: 0.6940, Validation Loss: 0.6929, Validation Accuracy: 50.76%\n",
      "Epoch  1, Batch 23: \n",
      "Training Loss: 0.6933, Validation Loss: 0.6913, Validation Accuracy: 52.00%\n",
      "Epoch  1, Batch 24: \n",
      "Training Loss: 0.6895, Validation Loss: 0.6900, Validation Accuracy: 54.64%\n",
      "Epoch  1, Batch 25: \n",
      "Training Loss: 0.6885, Validation Loss: 0.6894, Validation Accuracy: 57.92%\n",
      "Epoch  1, Batch 26: \n",
      "Training Loss: 0.6889, Validation Loss: 0.6894, Validation Accuracy: 55.32%\n",
      "Epoch  1, Batch 27: \n",
      "Training Loss: 0.6904, Validation Loss: 0.6894, Validation Accuracy: 51.84%\n",
      "Epoch  1, Batch 28: \n",
      "Training Loss: 0.6911, Validation Loss: 0.6894, Validation Accuracy: 51.56%\n",
      "Epoch  1, Batch 29: \n",
      "Training Loss: 0.6892, Validation Loss: 0.6894, Validation Accuracy: 50.84%\n",
      "Epoch  1, Batch 30: \n",
      "Training Loss: 0.6918, Validation Loss: 0.6895, Validation Accuracy: 50.64%\n",
      "Epoch  1, Batch 31: \n",
      "Training Loss: 0.6891, Validation Loss: 0.6895, Validation Accuracy: 50.52%\n",
      "Epoch  1, Batch 32: \n",
      "Training Loss: 0.6893, Validation Loss: 0.6895, Validation Accuracy: 50.56%\n",
      "Epoch  1, Batch 33: \n",
      "Training Loss: 0.6906, Validation Loss: 0.6894, Validation Accuracy: 50.52%\n",
      "Epoch  1, Batch 34: \n",
      "Training Loss: 0.6969, Validation Loss: 0.6894, Validation Accuracy: 50.72%\n",
      "Epoch  1, Batch 35: \n",
      "Training Loss: 0.6884, Validation Loss: 0.6893, Validation Accuracy: 50.96%\n",
      "Epoch  1, Batch 36: \n",
      "Training Loss: 0.6913, Validation Loss: 0.6893, Validation Accuracy: 51.20%\n",
      "Epoch  1, Batch 37: \n",
      "Training Loss: 0.6920, Validation Loss: 0.6892, Validation Accuracy: 51.20%\n",
      "Epoch  1, Batch 38: \n",
      "Training Loss: 0.6887, Validation Loss: 0.6892, Validation Accuracy: 51.28%\n",
      "Epoch  1, Batch 39: \n",
      "Training Loss: 0.6895, Validation Loss: 0.6891, Validation Accuracy: 51.36%\n",
      "Epoch  1, Batch 40: \n",
      "Training Loss: 0.6874, Validation Loss: 0.6891, Validation Accuracy: 52.04%\n",
      "Epoch  1, Batch 41: \n",
      "Training Loss: 0.6898, Validation Loss: 0.6890, Validation Accuracy: 52.44%\n",
      "Epoch  1, Batch 42: \n",
      "Training Loss: 0.6913, Validation Loss: 0.6889, Validation Accuracy: 53.08%\n",
      "Epoch  1, Batch 43: \n",
      "Training Loss: 0.6879, Validation Loss: 0.6888, Validation Accuracy: 54.32%\n",
      "Epoch  1, Batch 44: \n",
      "Training Loss: 0.6883, Validation Loss: 0.6888, Validation Accuracy: 55.80%\n",
      "Epoch  1, Batch 45: \n",
      "Training Loss: 0.6893, Validation Loss: 0.6887, Validation Accuracy: 55.84%\n",
      "Epoch  1, Batch 46: \n",
      "Training Loss: 0.6874, Validation Loss: 0.6885, Validation Accuracy: 56.16%\n",
      "Epoch  1, Batch 47: \n",
      "Training Loss: 0.6868, Validation Loss: 0.6884, Validation Accuracy: 57.12%\n",
      "Epoch  1, Batch 48: \n",
      "Training Loss: 0.6920, Validation Loss: 0.6883, Validation Accuracy: 58.00%\n",
      "Epoch  1, Batch 49: \n",
      "Training Loss: 0.6895, Validation Loss: 0.6882, Validation Accuracy: 59.36%\n",
      "Epoch  1, Batch 50: \n",
      "Training Loss: 0.6890, Validation Loss: 0.6880, Validation Accuracy: 59.64%\n",
      "Epoch  1, Batch 51: \n",
      "Training Loss: 0.6863, Validation Loss: 0.6878, Validation Accuracy: 59.40%\n",
      "Epoch  1, Batch 52: \n",
      "Training Loss: 0.6881, Validation Loss: 0.6876, Validation Accuracy: 58.88%\n",
      "Epoch  1, Batch 53: \n",
      "Training Loss: 0.6867, Validation Loss: 0.6874, Validation Accuracy: 57.32%\n",
      "Epoch  1, Batch 54: \n",
      "Training Loss: 0.6851, Validation Loss: 0.6871, Validation Accuracy: 56.12%\n",
      "Epoch  1, Batch 55: \n",
      "Training Loss: 0.6875, Validation Loss: 0.6869, Validation Accuracy: 55.28%\n",
      "Epoch  1, Batch 56: \n",
      "Training Loss: 0.6861, Validation Loss: 0.6868, Validation Accuracy: 54.12%\n",
      "Epoch  1, Batch 57: \n",
      "Training Loss: 0.6882, Validation Loss: 0.6867, Validation Accuracy: 52.52%\n",
      "Epoch  1, Batch 58: \n",
      "Training Loss: 0.6845, Validation Loss: 0.6866, Validation Accuracy: 52.36%\n",
      "Epoch  1, Batch 59: \n",
      "Training Loss: 0.6839, Validation Loss: 0.6864, Validation Accuracy: 52.08%\n",
      "Epoch  1, Batch 60: \n",
      "Training Loss: 0.6930, Validation Loss: 0.6864, Validation Accuracy: 51.80%\n",
      "Epoch  1, Batch 61: \n",
      "Training Loss: 0.6882, Validation Loss: 0.6862, Validation Accuracy: 51.92%\n",
      "Epoch  1, Batch 62: \n",
      "Training Loss: 0.6979, Validation Loss: 0.6861, Validation Accuracy: 52.48%\n",
      "Epoch  1, Batch 63: \n",
      "Training Loss: 0.6831, Validation Loss: 0.6859, Validation Accuracy: 52.84%\n",
      "Epoch  1, Batch 64: \n",
      "Training Loss: 0.6841, Validation Loss: 0.6857, Validation Accuracy: 54.36%\n",
      "Epoch  1, Batch 65: \n",
      "Training Loss: 0.6888, Validation Loss: 0.6855, Validation Accuracy: 55.32%\n",
      "Epoch  1, Batch 66: \n",
      "Training Loss: 0.6826, Validation Loss: 0.6854, Validation Accuracy: 57.12%\n",
      "Epoch  1, Batch 67: \n",
      "Training Loss: 0.6837, Validation Loss: 0.6852, Validation Accuracy: 59.16%\n",
      "Epoch  1, Batch 68: \n",
      "Training Loss: 0.6832, Validation Loss: 0.6851, Validation Accuracy: 59.88%\n",
      "Epoch  1, Batch 69: \n",
      "Training Loss: 0.6829, Validation Loss: 0.6849, Validation Accuracy: 60.36%\n",
      "Epoch  1, Batch 70: \n",
      "Training Loss: 0.6820, Validation Loss: 0.6847, Validation Accuracy: 61.60%\n",
      "Epoch  1, Batch 71: \n",
      "Training Loss: 0.6838, Validation Loss: 0.6845, Validation Accuracy: 60.96%\n",
      "Epoch  1, Batch 72: \n",
      "Training Loss: 0.6855, Validation Loss: 0.6842, Validation Accuracy: 60.96%\n",
      "Epoch  1, Batch 73: \n",
      "Training Loss: 0.6848, Validation Loss: 0.6840, Validation Accuracy: 60.36%\n",
      "Epoch  1, Batch 74: \n",
      "Training Loss: 0.6760, Validation Loss: 0.6838, Validation Accuracy: 59.28%\n",
      "Epoch  1, Batch 75: \n",
      "Training Loss: 0.6846, Validation Loss: 0.6835, Validation Accuracy: 59.00%\n",
      "Epoch  1, Batch 76: \n",
      "Training Loss: 0.6791, Validation Loss: 0.6831, Validation Accuracy: 58.80%\n",
      "Epoch  1, Batch 77: \n",
      "Training Loss: 0.6773, Validation Loss: 0.6825, Validation Accuracy: 59.40%\n",
      "Epoch  1, Batch 78: \n",
      "Training Loss: 0.6787, Validation Loss: 0.6820, Validation Accuracy: 59.80%\n",
      "Epoch  1, Batch 79: \n",
      "Training Loss: 0.6799, Validation Loss: 0.6809, Validation Accuracy: 61.52%\n",
      "Epoch  1, Batch 80: \n",
      "Training Loss: 0.6759, Validation Loss: 0.6798, Validation Accuracy: 62.24%\n",
      "Epoch  1, Batch 81: \n",
      "Training Loss: 0.6721, Validation Loss: 0.6789, Validation Accuracy: 60.76%\n",
      "Epoch  1, Batch 82: \n",
      "Training Loss: 0.6708, Validation Loss: 0.6781, Validation Accuracy: 60.08%\n",
      "Epoch  1, Batch 83: \n",
      "Training Loss: 0.6722, Validation Loss: 0.6778, Validation Accuracy: 58.08%\n",
      "Epoch  1, Batch 84: \n",
      "Training Loss: 0.6781, Validation Loss: 0.6772, Validation Accuracy: 59.00%\n",
      "Epoch  1, Batch 85: \n",
      "Training Loss: 0.6736, Validation Loss: 0.6768, Validation Accuracy: 60.08%\n",
      "Epoch  1, Batch 86: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6681, Validation Loss: 0.6763, Validation Accuracy: 60.36%\n",
      "Epoch  1, Batch 87: \n",
      "Training Loss: 0.6709, Validation Loss: 0.6757, Validation Accuracy: 61.36%\n",
      "Epoch  1, Batch 88: \n",
      "Training Loss: 0.6668, Validation Loss: 0.6750, Validation Accuracy: 62.08%\n",
      "Epoch  2, Batch 1: \n",
      "Training Loss: 0.6725, Validation Loss: 0.6743, Validation Accuracy: 62.08%\n",
      "Epoch  2, Batch 2: \n",
      "Training Loss: 0.6591, Validation Loss: 0.6738, Validation Accuracy: 61.68%\n",
      "Epoch  2, Batch 3: \n",
      "Training Loss: 0.6638, Validation Loss: 0.6728, Validation Accuracy: 61.84%\n",
      "Epoch  2, Batch 4: \n",
      "Training Loss: 0.6759, Validation Loss: 0.6716, Validation Accuracy: 61.72%\n",
      "Epoch  2, Batch 5: \n",
      "Training Loss: 0.6698, Validation Loss: 0.6705, Validation Accuracy: 62.08%\n",
      "Epoch  2, Batch 6: \n",
      "Training Loss: 0.6726, Validation Loss: 0.6699, Validation Accuracy: 62.44%\n",
      "Epoch  2, Batch 7: \n",
      "Training Loss: 0.6585, Validation Loss: 0.6688, Validation Accuracy: 61.88%\n",
      "Epoch  2, Batch 8: \n",
      "Training Loss: 0.6639, Validation Loss: 0.6678, Validation Accuracy: 62.00%\n",
      "Epoch  2, Batch 9: \n",
      "Training Loss: 0.6769, Validation Loss: 0.6671, Validation Accuracy: 62.20%\n",
      "Epoch  2, Batch 10: \n",
      "Training Loss: 0.6517, Validation Loss: 0.6667, Validation Accuracy: 61.28%\n",
      "Epoch  2, Batch 11: \n",
      "Training Loss: 0.6560, Validation Loss: 0.6672, Validation Accuracy: 59.76%\n",
      "Epoch  2, Batch 12: \n",
      "Training Loss: 0.6592, Validation Loss: 0.6654, Validation Accuracy: 61.12%\n",
      "Epoch  2, Batch 13: \n",
      "Training Loss: 0.6550, Validation Loss: 0.6644, Validation Accuracy: 61.96%\n",
      "Epoch  2, Batch 14: \n",
      "Training Loss: 0.6603, Validation Loss: 0.6644, Validation Accuracy: 61.96%\n",
      "Epoch  2, Batch 15: \n",
      "Training Loss: 0.6615, Validation Loss: 0.6641, Validation Accuracy: 62.28%\n",
      "Epoch  2, Batch 16: \n",
      "Training Loss: 0.6685, Validation Loss: 0.6638, Validation Accuracy: 62.36%\n",
      "Epoch  2, Batch 17: \n",
      "Training Loss: 0.6645, Validation Loss: 0.6632, Validation Accuracy: 62.48%\n",
      "Epoch  2, Batch 18: \n",
      "Training Loss: 0.6676, Validation Loss: 0.6629, Validation Accuracy: 62.44%\n",
      "Epoch  2, Batch 19: \n",
      "Training Loss: 0.6440, Validation Loss: 0.6621, Validation Accuracy: 62.52%\n",
      "Epoch  2, Batch 20: \n",
      "Training Loss: 0.6527, Validation Loss: 0.6612, Validation Accuracy: 62.40%\n",
      "Epoch  2, Batch 21: \n",
      "Training Loss: 0.6621, Validation Loss: 0.6603, Validation Accuracy: 62.24%\n",
      "Epoch  2, Batch 22: \n",
      "Training Loss: 0.6733, Validation Loss: 0.6596, Validation Accuracy: 62.48%\n",
      "Epoch  2, Batch 23: \n",
      "Training Loss: 0.6515, Validation Loss: 0.6589, Validation Accuracy: 62.44%\n",
      "Epoch  2, Batch 24: \n",
      "Training Loss: 0.6396, Validation Loss: 0.6582, Validation Accuracy: 62.08%\n",
      "Epoch  2, Batch 25: \n",
      "Training Loss: 0.6546, Validation Loss: 0.6573, Validation Accuracy: 62.44%\n",
      "Epoch  2, Batch 26: \n",
      "Training Loss: 0.6543, Validation Loss: 0.6564, Validation Accuracy: 62.68%\n",
      "Epoch  2, Batch 27: \n",
      "Training Loss: 0.6536, Validation Loss: 0.6555, Validation Accuracy: 62.84%\n",
      "Epoch  2, Batch 28: \n",
      "Training Loss: 0.6462, Validation Loss: 0.6548, Validation Accuracy: 63.04%\n",
      "Epoch  2, Batch 29: \n",
      "Training Loss: 0.6432, Validation Loss: 0.6540, Validation Accuracy: 62.76%\n",
      "Epoch  2, Batch 30: \n",
      "Training Loss: 0.6376, Validation Loss: 0.6541, Validation Accuracy: 63.20%\n",
      "Epoch  2, Batch 31: \n",
      "Training Loss: 0.6353, Validation Loss: 0.6550, Validation Accuracy: 62.76%\n",
      "Epoch  2, Batch 32: \n",
      "Training Loss: 0.6487, Validation Loss: 0.6553, Validation Accuracy: 62.48%\n",
      "Epoch  2, Batch 33: \n",
      "Training Loss: 0.6562, Validation Loss: 0.6544, Validation Accuracy: 62.52%\n",
      "Epoch  2, Batch 34: \n",
      "Training Loss: 0.6555, Validation Loss: 0.6534, Validation Accuracy: 62.88%\n",
      "Epoch  2, Batch 35: \n",
      "Training Loss: 0.6314, Validation Loss: 0.6508, Validation Accuracy: 63.48%\n",
      "Epoch  2, Batch 36: \n",
      "Training Loss: 0.6480, Validation Loss: 0.6487, Validation Accuracy: 63.60%\n",
      "Epoch  2, Batch 37: \n",
      "Training Loss: 0.6600, Validation Loss: 0.6480, Validation Accuracy: 63.64%\n",
      "Epoch  2, Batch 38: \n",
      "Training Loss: 0.6233, Validation Loss: 0.6485, Validation Accuracy: 63.56%\n",
      "Epoch  2, Batch 39: \n",
      "Training Loss: 0.6517, Validation Loss: 0.6502, Validation Accuracy: 62.72%\n",
      "Epoch  2, Batch 40: \n",
      "Training Loss: 0.6319, Validation Loss: 0.6510, Validation Accuracy: 62.20%\n",
      "Epoch  2, Batch 41: \n",
      "Training Loss: 0.6532, Validation Loss: 0.6494, Validation Accuracy: 62.60%\n",
      "Epoch  2, Batch 42: \n",
      "Training Loss: 0.6471, Validation Loss: 0.6460, Validation Accuracy: 64.28%\n",
      "Epoch  2, Batch 43: \n",
      "Training Loss: 0.6312, Validation Loss: 0.6465, Validation Accuracy: 65.08%\n",
      "Epoch  2, Batch 44: \n",
      "Training Loss: 0.6134, Validation Loss: 0.6503, Validation Accuracy: 64.04%\n",
      "Epoch  2, Batch 45: \n",
      "Training Loss: 0.6511, Validation Loss: 0.6499, Validation Accuracy: 63.96%\n",
      "Epoch  2, Batch 46: \n",
      "Training Loss: 0.6303, Validation Loss: 0.6480, Validation Accuracy: 64.80%\n",
      "Epoch  2, Batch 47: \n",
      "Training Loss: 0.6135, Validation Loss: 0.6454, Validation Accuracy: 65.52%\n",
      "Epoch  2, Batch 48: \n",
      "Training Loss: 0.6378, Validation Loss: 0.6439, Validation Accuracy: 65.96%\n",
      "Epoch  2, Batch 49: \n",
      "Training Loss: 0.6243, Validation Loss: 0.6424, Validation Accuracy: 65.76%\n",
      "Epoch  2, Batch 50: \n",
      "Training Loss: 0.6578, Validation Loss: 0.6415, Validation Accuracy: 64.80%\n",
      "Epoch  2, Batch 51: \n",
      "Training Loss: 0.6165, Validation Loss: 0.6427, Validation Accuracy: 63.88%\n",
      "Epoch  2, Batch 52: \n",
      "Training Loss: 0.6225, Validation Loss: 0.6432, Validation Accuracy: 63.40%\n",
      "Epoch  2, Batch 53: \n",
      "Training Loss: 0.6195, Validation Loss: 0.6413, Validation Accuracy: 64.20%\n",
      "Epoch  2, Batch 54: \n",
      "Training Loss: 0.6036, Validation Loss: 0.6381, Validation Accuracy: 64.88%\n",
      "Epoch  2, Batch 55: \n",
      "Training Loss: 0.6354, Validation Loss: 0.6358, Validation Accuracy: 65.68%\n",
      "Epoch  2, Batch 56: \n",
      "Training Loss: 0.6317, Validation Loss: 0.6352, Validation Accuracy: 65.76%\n",
      "Epoch  2, Batch 57: \n",
      "Training Loss: 0.6390, Validation Loss: 0.6361, Validation Accuracy: 65.76%\n",
      "Epoch  2, Batch 58: \n",
      "Training Loss: 0.5927, Validation Loss: 0.6352, Validation Accuracy: 65.96%\n",
      "Epoch  2, Batch 59: \n",
      "Training Loss: 0.6280, Validation Loss: 0.6317, Validation Accuracy: 65.96%\n",
      "Epoch  2, Batch 60: \n",
      "Training Loss: 0.6311, Validation Loss: 0.6298, Validation Accuracy: 66.04%\n",
      "Epoch  2, Batch 61: \n",
      "Training Loss: 0.6074, Validation Loss: 0.6284, Validation Accuracy: 66.08%\n",
      "Epoch  2, Batch 62: \n",
      "Training Loss: 0.6218, Validation Loss: 0.6301, Validation Accuracy: 65.76%\n",
      "Epoch  2, Batch 63: \n",
      "Training Loss: 0.5930, Validation Loss: 0.6298, Validation Accuracy: 65.88%\n",
      "Epoch  2, Batch 64: \n",
      "Training Loss: 0.5865, Validation Loss: 0.6264, Validation Accuracy: 66.04%\n",
      "Epoch  2, Batch 65: \n",
      "Training Loss: 0.6124, Validation Loss: 0.6245, Validation Accuracy: 65.80%\n",
      "Epoch  2, Batch 66: \n",
      "Training Loss: 0.5887, Validation Loss: 0.6255, Validation Accuracy: 65.84%\n",
      "Epoch  2, Batch 67: \n",
      "Training Loss: 0.6103, Validation Loss: 0.6247, Validation Accuracy: 65.68%\n",
      "Epoch  2, Batch 68: \n",
      "Training Loss: 0.6290, Validation Loss: 0.6221, Validation Accuracy: 66.12%\n",
      "Epoch  2, Batch 69: \n",
      "Training Loss: 0.5998, Validation Loss: 0.6212, Validation Accuracy: 66.72%\n",
      "Epoch  2, Batch 70: \n",
      "Training Loss: 0.6202, Validation Loss: 0.6214, Validation Accuracy: 66.44%\n",
      "Epoch  2, Batch 71: \n",
      "Training Loss: 0.6072, Validation Loss: 0.6219, Validation Accuracy: 66.12%\n",
      "Epoch  2, Batch 72: \n",
      "Training Loss: 0.6233, Validation Loss: 0.6230, Validation Accuracy: 65.88%\n",
      "Epoch  2, Batch 73: \n",
      "Training Loss: 0.6170, Validation Loss: 0.6213, Validation Accuracy: 66.12%\n",
      "Epoch  2, Batch 74: \n",
      "Training Loss: 0.5707, Validation Loss: 0.6224, Validation Accuracy: 66.72%\n",
      "Epoch  2, Batch 75: \n",
      "Training Loss: 0.6232, Validation Loss: 0.6277, Validation Accuracy: 65.40%\n",
      "Epoch  2, Batch 76: \n",
      "Training Loss: 0.6081, Validation Loss: 0.6320, Validation Accuracy: 64.96%\n",
      "Epoch  2, Batch 77: \n",
      "Training Loss: 0.5991, Validation Loss: 0.6292, Validation Accuracy: 64.76%\n",
      "Epoch  2, Batch 78: \n",
      "Training Loss: 0.5962, Validation Loss: 0.6237, Validation Accuracy: 66.60%\n",
      "Epoch  2, Batch 79: \n",
      "Training Loss: 0.5993, Validation Loss: 0.6174, Validation Accuracy: 67.24%\n",
      "Epoch  2, Batch 80: \n",
      "Training Loss: 0.5753, Validation Loss: 0.6154, Validation Accuracy: 66.84%\n",
      "Epoch  2, Batch 81: \n",
      "Training Loss: 0.5762, Validation Loss: 0.6166, Validation Accuracy: 66.08%\n",
      "Epoch  2, Batch 82: \n",
      "Training Loss: 0.5818, Validation Loss: 0.6175, Validation Accuracy: 65.44%\n",
      "Epoch  2, Batch 83: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.6140, Validation Loss: 0.6145, Validation Accuracy: 66.32%\n",
      "Epoch  2, Batch 84: \n",
      "Training Loss: 0.5904, Validation Loss: 0.6100, Validation Accuracy: 67.44%\n",
      "Epoch  2, Batch 85: \n",
      "Training Loss: 0.5750, Validation Loss: 0.6130, Validation Accuracy: 67.52%\n",
      "Epoch  2, Batch 86: \n",
      "Training Loss: 0.5858, Validation Loss: 0.6132, Validation Accuracy: 67.52%\n",
      "Epoch  2, Batch 87: \n",
      "Training Loss: 0.5790, Validation Loss: 0.6117, Validation Accuracy: 67.32%\n",
      "Epoch  2, Batch 88: \n",
      "Training Loss: 0.5956, Validation Loss: 0.6098, Validation Accuracy: 67.28%\n",
      "Epoch  3, Batch 1: \n",
      "Training Loss: 0.6133, Validation Loss: 0.6083, Validation Accuracy: 67.72%\n",
      "Epoch  3, Batch 2: \n",
      "Training Loss: 0.5562, Validation Loss: 0.6085, Validation Accuracy: 67.56%\n",
      "Epoch  3, Batch 3: \n",
      "Training Loss: 0.5856, Validation Loss: 0.6096, Validation Accuracy: 67.32%\n",
      "Epoch  3, Batch 4: \n",
      "Training Loss: 0.6161, Validation Loss: 0.6070, Validation Accuracy: 67.88%\n",
      "Epoch  3, Batch 5: \n",
      "Training Loss: 0.5760, Validation Loss: 0.6045, Validation Accuracy: 67.84%\n",
      "Epoch  3, Batch 6: \n",
      "Training Loss: 0.6172, Validation Loss: 0.6071, Validation Accuracy: 68.24%\n",
      "Epoch  3, Batch 7: \n",
      "Training Loss: 0.5769, Validation Loss: 0.6112, Validation Accuracy: 67.80%\n",
      "Epoch  3, Batch 8: \n",
      "Training Loss: 0.5841, Validation Loss: 0.6108, Validation Accuracy: 67.64%\n",
      "Epoch  3, Batch 9: \n",
      "Training Loss: 0.6163, Validation Loss: 0.6041, Validation Accuracy: 69.72%\n",
      "Epoch  3, Batch 10: \n",
      "Training Loss: 0.5807, Validation Loss: 0.6035, Validation Accuracy: 68.36%\n",
      "Epoch  3, Batch 11: \n",
      "Training Loss: 0.5786, Validation Loss: 0.6141, Validation Accuracy: 64.48%\n",
      "Epoch  3, Batch 12: \n",
      "Training Loss: 0.6140, Validation Loss: 0.6126, Validation Accuracy: 64.96%\n",
      "Epoch  3, Batch 13: \n",
      "Training Loss: 0.5829, Validation Loss: 0.6046, Validation Accuracy: 67.92%\n",
      "Epoch  3, Batch 14: \n",
      "Training Loss: 0.5918, Validation Loss: 0.6002, Validation Accuracy: 68.88%\n",
      "Epoch  3, Batch 15: \n",
      "Training Loss: 0.6034, Validation Loss: 0.6019, Validation Accuracy: 69.48%\n",
      "Epoch  3, Batch 16: \n",
      "Training Loss: 0.6073, Validation Loss: 0.6051, Validation Accuracy: 68.80%\n",
      "Epoch  3, Batch 17: \n",
      "Training Loss: 0.5963, Validation Loss: 0.6074, Validation Accuracy: 68.40%\n",
      "Epoch  3, Batch 18: \n",
      "Training Loss: 0.6009, Validation Loss: 0.6078, Validation Accuracy: 68.36%\n",
      "Epoch  3, Batch 19: \n",
      "Training Loss: 0.5639, Validation Loss: 0.6025, Validation Accuracy: 68.88%\n",
      "Epoch  3, Batch 20: \n",
      "Training Loss: 0.5949, Validation Loss: 0.5974, Validation Accuracy: 69.32%\n",
      "Epoch  3, Batch 21: \n",
      "Training Loss: 0.6062, Validation Loss: 0.5963, Validation Accuracy: 68.80%\n",
      "Epoch  3, Batch 22: \n",
      "Training Loss: 0.6367, Validation Loss: 0.5984, Validation Accuracy: 68.40%\n",
      "Epoch  3, Batch 23: \n",
      "Training Loss: 0.5567, Validation Loss: 0.5980, Validation Accuracy: 68.52%\n",
      "Epoch  3, Batch 24: \n",
      "Training Loss: 0.5495, Validation Loss: 0.5954, Validation Accuracy: 68.92%\n",
      "Epoch  3, Batch 25: \n",
      "Training Loss: 0.5608, Validation Loss: 0.5950, Validation Accuracy: 69.32%\n",
      "Epoch  3, Batch 26: \n",
      "Training Loss: 0.6005, Validation Loss: 0.6000, Validation Accuracy: 68.80%\n",
      "Epoch  3, Batch 27: \n",
      "Training Loss: 0.5931, Validation Loss: 0.5984, Validation Accuracy: 69.24%\n",
      "Epoch  3, Batch 28: \n",
      "Training Loss: 0.5826, Validation Loss: 0.5936, Validation Accuracy: 69.32%\n",
      "Epoch  3, Batch 29: \n",
      "Training Loss: 0.5868, Validation Loss: 0.5929, Validation Accuracy: 69.40%\n",
      "Epoch  3, Batch 30: \n",
      "Training Loss: 0.5725, Validation Loss: 0.5929, Validation Accuracy: 69.16%\n",
      "Epoch  3, Batch 31: \n",
      "Training Loss: 0.5542, Validation Loss: 0.5922, Validation Accuracy: 69.92%\n",
      "Epoch  3, Batch 32: \n",
      "Training Loss: 0.5750, Validation Loss: 0.5919, Validation Accuracy: 69.96%\n",
      "Epoch  3, Batch 33: \n",
      "Training Loss: 0.5842, Validation Loss: 0.5914, Validation Accuracy: 69.72%\n",
      "Epoch  3, Batch 34: \n",
      "Training Loss: 0.6139, Validation Loss: 0.5940, Validation Accuracy: 69.72%\n",
      "Epoch  3, Batch 35: \n",
      "Training Loss: 0.5754, Validation Loss: 0.5936, Validation Accuracy: 69.48%\n",
      "Epoch  3, Batch 36: \n",
      "Training Loss: 0.5558, Validation Loss: 0.5913, Validation Accuracy: 69.96%\n",
      "Epoch  3, Batch 37: \n",
      "Training Loss: 0.5904, Validation Loss: 0.5882, Validation Accuracy: 70.04%\n",
      "Epoch  3, Batch 38: \n",
      "Training Loss: 0.5384, Validation Loss: 0.5856, Validation Accuracy: 70.04%\n",
      "Epoch  3, Batch 39: \n",
      "Training Loss: 0.5823, Validation Loss: 0.5867, Validation Accuracy: 69.84%\n",
      "Epoch  3, Batch 40: \n",
      "Training Loss: 0.5376, Validation Loss: 0.5891, Validation Accuracy: 69.00%\n",
      "Epoch  3, Batch 41: \n",
      "Training Loss: 0.6015, Validation Loss: 0.5869, Validation Accuracy: 69.40%\n",
      "Epoch  3, Batch 42: \n",
      "Training Loss: 0.5794, Validation Loss: 0.6298, Validation Accuracy: 65.72%\n",
      "Epoch  3, Batch 43: \n",
      "Training Loss: 0.5567, Validation Loss: 0.5929, Validation Accuracy: 68.60%\n",
      "Epoch  3, Batch 44: \n",
      "Training Loss: 0.5256, Validation Loss: 0.5848, Validation Accuracy: 69.48%\n",
      "Epoch  3, Batch 45: \n",
      "Training Loss: 0.5676, Validation Loss: 0.5878, Validation Accuracy: 68.80%\n",
      "Epoch  3, Batch 46: \n",
      "Training Loss: 0.5540, Validation Loss: 0.5865, Validation Accuracy: 68.96%\n",
      "Epoch  3, Batch 47: \n",
      "Training Loss: 0.5412, Validation Loss: 0.5822, Validation Accuracy: 69.64%\n",
      "Epoch  3, Batch 48: \n",
      "Training Loss: 0.5546, Validation Loss: 0.5857, Validation Accuracy: 69.92%\n",
      "Epoch  3, Batch 49: \n",
      "Training Loss: 0.5644, Validation Loss: 0.5924, Validation Accuracy: 69.64%\n",
      "Epoch  3, Batch 50: \n",
      "Training Loss: 0.5709, Validation Loss: 0.5947, Validation Accuracy: 69.40%\n",
      "Epoch  3, Batch 51: \n",
      "Training Loss: 0.5513, Validation Loss: 0.5876, Validation Accuracy: 69.96%\n",
      "Epoch  3, Batch 52: \n",
      "Training Loss: 0.5464, Validation Loss: 0.5848, Validation Accuracy: 69.96%\n",
      "Epoch  3, Batch 53: \n",
      "Training Loss: 0.5409, Validation Loss: 0.5858, Validation Accuracy: 69.36%\n",
      "Epoch  3, Batch 54: \n",
      "Training Loss: 0.5391, Validation Loss: 0.5880, Validation Accuracy: 68.56%\n",
      "Epoch  3, Batch 55: \n",
      "Training Loss: 0.6016, Validation Loss: 0.5840, Validation Accuracy: 69.00%\n",
      "Epoch  3, Batch 56: \n",
      "Training Loss: 0.5650, Validation Loss: 0.5799, Validation Accuracy: 70.12%\n",
      "Epoch  3, Batch 57: \n",
      "Training Loss: 0.5821, Validation Loss: 0.5798, Validation Accuracy: 69.96%\n",
      "Epoch  3, Batch 58: \n",
      "Training Loss: 0.5191, Validation Loss: 0.5820, Validation Accuracy: 70.08%\n",
      "Epoch  3, Batch 59: \n",
      "Training Loss: 0.5566, Validation Loss: 0.5773, Validation Accuracy: 69.96%\n",
      "Epoch  3, Batch 60: \n",
      "Training Loss: 0.5712, Validation Loss: 0.5761, Validation Accuracy: 70.16%\n",
      "Epoch  3, Batch 61: \n",
      "Training Loss: 0.5520, Validation Loss: 0.5744, Validation Accuracy: 69.60%\n",
      "Epoch  3, Batch 62: \n",
      "Training Loss: 0.5687, Validation Loss: 0.5776, Validation Accuracy: 70.52%\n",
      "Epoch  3, Batch 63: \n",
      "Training Loss: 0.5285, Validation Loss: 0.5797, Validation Accuracy: 70.32%\n",
      "Epoch  3, Batch 64: \n",
      "Training Loss: 0.5184, Validation Loss: 0.5781, Validation Accuracy: 70.48%\n",
      "Epoch  3, Batch 65: \n",
      "Training Loss: 0.5416, Validation Loss: 0.5814, Validation Accuracy: 70.00%\n",
      "Epoch  3, Batch 66: \n",
      "Training Loss: 0.5276, Validation Loss: 0.5831, Validation Accuracy: 69.68%\n",
      "Epoch  3, Batch 67: \n",
      "Training Loss: 0.5629, Validation Loss: 0.5741, Validation Accuracy: 70.36%\n",
      "Epoch  3, Batch 68: \n",
      "Training Loss: 0.5628, Validation Loss: 0.5681, Validation Accuracy: 70.20%\n",
      "Epoch  3, Batch 69: \n",
      "Training Loss: 0.5266, Validation Loss: 0.5716, Validation Accuracy: 69.88%\n",
      "Epoch  3, Batch 70: \n",
      "Training Loss: 0.5682, Validation Loss: 0.5679, Validation Accuracy: 70.24%\n",
      "Epoch  3, Batch 71: \n",
      "Training Loss: 0.5515, Validation Loss: 0.5672, Validation Accuracy: 70.44%\n",
      "Epoch  3, Batch 72: \n",
      "Training Loss: 0.5737, Validation Loss: 0.5671, Validation Accuracy: 70.32%\n",
      "Epoch  3, Batch 73: \n",
      "Training Loss: 0.5497, Validation Loss: 0.5692, Validation Accuracy: 70.56%\n",
      "Epoch  3, Batch 74: \n",
      "Training Loss: 0.5024, Validation Loss: 0.5727, Validation Accuracy: 70.60%\n",
      "Epoch  3, Batch 75: \n",
      "Training Loss: 0.5603, Validation Loss: 0.5713, Validation Accuracy: 70.68%\n",
      "Epoch  3, Batch 76: \n",
      "Training Loss: 0.5370, Validation Loss: 0.5682, Validation Accuracy: 70.60%\n",
      "Epoch  3, Batch 77: \n",
      "Training Loss: 0.5206, Validation Loss: 0.5665, Validation Accuracy: 70.36%\n",
      "Epoch  3, Batch 78: \n",
      "Training Loss: 0.5195, Validation Loss: 0.5662, Validation Accuracy: 70.24%\n",
      "Epoch  3, Batch 79: \n",
      "Training Loss: 0.5205, Validation Loss: 0.5662, Validation Accuracy: 70.40%\n",
      "Epoch  3, Batch 80: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4862, Validation Loss: 0.5671, Validation Accuracy: 70.32%\n",
      "Epoch  3, Batch 81: \n",
      "Training Loss: 0.4856, Validation Loss: 0.5665, Validation Accuracy: 70.60%\n",
      "Epoch  3, Batch 82: \n",
      "Training Loss: 0.5137, Validation Loss: 0.5643, Validation Accuracy: 70.36%\n",
      "Epoch  3, Batch 83: \n",
      "Training Loss: 0.5686, Validation Loss: 0.5699, Validation Accuracy: 70.20%\n",
      "Epoch  3, Batch 84: \n",
      "Training Loss: 0.5461, Validation Loss: 0.5645, Validation Accuracy: 70.40%\n",
      "Epoch  3, Batch 85: \n",
      "Training Loss: 0.5127, Validation Loss: 0.5635, Validation Accuracy: 70.44%\n",
      "Epoch  3, Batch 86: \n",
      "Training Loss: 0.5029, Validation Loss: 0.5623, Validation Accuracy: 70.80%\n",
      "Epoch  3, Batch 87: \n",
      "Training Loss: 0.5297, Validation Loss: 0.5619, Validation Accuracy: 70.76%\n",
      "Epoch  3, Batch 88: \n",
      "Training Loss: 0.5299, Validation Loss: 0.5612, Validation Accuracy: 70.56%\n",
      "Epoch  4, Batch 1: \n",
      "Training Loss: 0.5586, Validation Loss: 0.5607, Validation Accuracy: 70.64%\n",
      "Epoch  4, Batch 2: \n",
      "Training Loss: 0.4970, Validation Loss: 0.5601, Validation Accuracy: 70.52%\n",
      "Epoch  4, Batch 3: \n",
      "Training Loss: 0.5472, Validation Loss: 0.5603, Validation Accuracy: 70.84%\n",
      "Epoch  4, Batch 4: \n",
      "Training Loss: 0.5503, Validation Loss: 0.5591, Validation Accuracy: 71.00%\n",
      "Epoch  4, Batch 5: \n",
      "Training Loss: 0.5054, Validation Loss: 0.5595, Validation Accuracy: 71.24%\n",
      "Epoch  4, Batch 6: \n",
      "Training Loss: 0.5612, Validation Loss: 0.5624, Validation Accuracy: 71.88%\n",
      "Epoch  4, Batch 7: \n",
      "Training Loss: 0.5299, Validation Loss: 0.5613, Validation Accuracy: 71.76%\n",
      "Epoch  4, Batch 8: \n",
      "Training Loss: 0.5280, Validation Loss: 0.5591, Validation Accuracy: 72.04%\n",
      "Epoch  4, Batch 9: \n",
      "Training Loss: 0.5625, Validation Loss: 0.5568, Validation Accuracy: 71.32%\n",
      "Epoch  4, Batch 10: \n",
      "Training Loss: 0.5338, Validation Loss: 0.5582, Validation Accuracy: 71.44%\n",
      "Epoch  4, Batch 11: \n",
      "Training Loss: 0.5137, Validation Loss: 0.5654, Validation Accuracy: 70.24%\n",
      "Epoch  4, Batch 12: \n",
      "Training Loss: 0.5703, Validation Loss: 0.5635, Validation Accuracy: 70.60%\n",
      "Epoch  4, Batch 13: \n",
      "Training Loss: 0.5438, Validation Loss: 0.5560, Validation Accuracy: 71.00%\n",
      "Epoch  4, Batch 14: \n",
      "Training Loss: 0.5312, Validation Loss: 0.5565, Validation Accuracy: 71.64%\n",
      "Epoch  4, Batch 15: \n",
      "Training Loss: 0.5379, Validation Loss: 0.5556, Validation Accuracy: 71.64%\n",
      "Epoch  4, Batch 16: \n",
      "Training Loss: 0.5540, Validation Loss: 0.5556, Validation Accuracy: 71.48%\n",
      "Epoch  4, Batch 17: \n",
      "Training Loss: 0.5277, Validation Loss: 0.5564, Validation Accuracy: 71.40%\n",
      "Epoch  4, Batch 18: \n",
      "Training Loss: 0.5528, Validation Loss: 0.5583, Validation Accuracy: 71.32%\n",
      "Epoch  4, Batch 19: \n",
      "Training Loss: 0.5058, Validation Loss: 0.5579, Validation Accuracy: 71.28%\n",
      "Epoch  4, Batch 20: \n",
      "Training Loss: 0.5611, Validation Loss: 0.5577, Validation Accuracy: 70.88%\n",
      "Epoch  4, Batch 21: \n",
      "Training Loss: 0.5546, Validation Loss: 0.5563, Validation Accuracy: 71.24%\n",
      "Epoch  4, Batch 22: \n",
      "Training Loss: 0.5923, Validation Loss: 0.5566, Validation Accuracy: 71.20%\n",
      "Epoch  4, Batch 23: \n",
      "Training Loss: 0.4976, Validation Loss: 0.5579, Validation Accuracy: 71.48%\n",
      "Epoch  4, Batch 24: \n",
      "Training Loss: 0.4868, Validation Loss: 0.5567, Validation Accuracy: 71.36%\n",
      "Epoch  4, Batch 25: \n",
      "Training Loss: 0.5094, Validation Loss: 0.5535, Validation Accuracy: 71.76%\n",
      "Epoch  4, Batch 26: \n",
      "Training Loss: 0.5544, Validation Loss: 0.5586, Validation Accuracy: 71.36%\n",
      "Epoch  4, Batch 27: \n",
      "Training Loss: 0.5536, Validation Loss: 0.5543, Validation Accuracy: 71.84%\n",
      "Epoch  4, Batch 28: \n",
      "Training Loss: 0.5301, Validation Loss: 0.5517, Validation Accuracy: 71.68%\n",
      "Epoch  4, Batch 29: \n",
      "Training Loss: 0.5372, Validation Loss: 0.5525, Validation Accuracy: 71.32%\n",
      "Epoch  4, Batch 30: \n",
      "Training Loss: 0.5179, Validation Loss: 0.5508, Validation Accuracy: 71.72%\n",
      "Epoch  4, Batch 31: \n",
      "Training Loss: 0.5045, Validation Loss: 0.5547, Validation Accuracy: 71.64%\n",
      "Epoch  4, Batch 32: \n",
      "Training Loss: 0.5286, Validation Loss: 0.5573, Validation Accuracy: 71.28%\n",
      "Epoch  4, Batch 33: \n",
      "Training Loss: 0.5351, Validation Loss: 0.5530, Validation Accuracy: 72.16%\n",
      "Epoch  4, Batch 34: \n",
      "Training Loss: 0.5806, Validation Loss: 0.5509, Validation Accuracy: 72.00%\n",
      "Epoch  4, Batch 35: \n",
      "Training Loss: 0.5220, Validation Loss: 0.5469, Validation Accuracy: 71.72%\n",
      "Epoch  4, Batch 36: \n",
      "Training Loss: 0.5091, Validation Loss: 0.5453, Validation Accuracy: 71.88%\n",
      "Epoch  4, Batch 37: \n",
      "Training Loss: 0.5246, Validation Loss: 0.5439, Validation Accuracy: 71.80%\n",
      "Epoch  4, Batch 38: \n",
      "Training Loss: 0.4921, Validation Loss: 0.5436, Validation Accuracy: 71.92%\n",
      "Epoch  4, Batch 39: \n",
      "Training Loss: 0.5304, Validation Loss: 0.5439, Validation Accuracy: 72.24%\n",
      "Epoch  4, Batch 40: \n",
      "Training Loss: 0.4904, Validation Loss: 0.5458, Validation Accuracy: 72.12%\n",
      "Epoch  4, Batch 41: \n",
      "Training Loss: 0.5532, Validation Loss: 0.5514, Validation Accuracy: 72.00%\n",
      "Epoch  4, Batch 42: \n",
      "Training Loss: 0.5219, Validation Loss: 0.5577, Validation Accuracy: 71.36%\n",
      "Epoch  4, Batch 43: \n",
      "Training Loss: 0.4976, Validation Loss: 0.5513, Validation Accuracy: 72.40%\n",
      "Epoch  4, Batch 44: \n",
      "Training Loss: 0.4841, Validation Loss: 0.5487, Validation Accuracy: 71.80%\n",
      "Epoch  4, Batch 45: \n",
      "Training Loss: 0.5112, Validation Loss: 0.5580, Validation Accuracy: 70.36%\n",
      "Epoch  4, Batch 46: \n",
      "Training Loss: 0.5088, Validation Loss: 0.5540, Validation Accuracy: 70.88%\n",
      "Epoch  4, Batch 47: \n",
      "Training Loss: 0.4965, Validation Loss: 0.5452, Validation Accuracy: 71.96%\n",
      "Epoch  4, Batch 48: \n",
      "Training Loss: 0.4977, Validation Loss: 0.5492, Validation Accuracy: 72.12%\n",
      "Epoch  4, Batch 49: \n",
      "Training Loss: 0.5237, Validation Loss: 0.5587, Validation Accuracy: 71.36%\n",
      "Epoch  4, Batch 50: \n",
      "Training Loss: 0.5110, Validation Loss: 0.5570, Validation Accuracy: 71.48%\n",
      "Epoch  4, Batch 51: \n",
      "Training Loss: 0.4903, Validation Loss: 0.5459, Validation Accuracy: 72.32%\n",
      "Epoch  4, Batch 52: \n",
      "Training Loss: 0.4824, Validation Loss: 0.5476, Validation Accuracy: 71.68%\n",
      "Epoch  4, Batch 53: \n",
      "Training Loss: 0.4856, Validation Loss: 0.5504, Validation Accuracy: 70.96%\n",
      "Epoch  4, Batch 54: \n",
      "Training Loss: 0.4722, Validation Loss: 0.5464, Validation Accuracy: 71.60%\n",
      "Epoch  4, Batch 55: \n",
      "Training Loss: 0.5436, Validation Loss: 0.5436, Validation Accuracy: 72.20%\n",
      "Epoch  4, Batch 56: \n",
      "Training Loss: 0.5178, Validation Loss: 0.5472, Validation Accuracy: 72.12%\n",
      "Epoch  4, Batch 57: \n",
      "Training Loss: 0.5420, Validation Loss: 0.5473, Validation Accuracy: 72.20%\n",
      "Epoch  4, Batch 58: \n",
      "Training Loss: 0.4638, Validation Loss: 0.5416, Validation Accuracy: 72.84%\n",
      "Epoch  4, Batch 59: \n",
      "Training Loss: 0.4938, Validation Loss: 0.5422, Validation Accuracy: 71.12%\n",
      "Epoch  4, Batch 60: \n",
      "Training Loss: 0.5418, Validation Loss: 0.5418, Validation Accuracy: 71.64%\n",
      "Epoch  4, Batch 61: \n",
      "Training Loss: 0.4892, Validation Loss: 0.5412, Validation Accuracy: 72.64%\n",
      "Epoch  4, Batch 62: \n",
      "Training Loss: 0.5321, Validation Loss: 0.5550, Validation Accuracy: 72.12%\n",
      "Epoch  4, Batch 63: \n",
      "Training Loss: 0.4930, Validation Loss: 0.5642, Validation Accuracy: 70.88%\n",
      "Epoch  4, Batch 64: \n",
      "Training Loss: 0.4933, Validation Loss: 0.5562, Validation Accuracy: 71.88%\n",
      "Epoch  4, Batch 65: \n",
      "Training Loss: 0.5088, Validation Loss: 0.5493, Validation Accuracy: 72.16%\n",
      "Epoch  4, Batch 66: \n",
      "Training Loss: 0.4955, Validation Loss: 0.5431, Validation Accuracy: 72.76%\n",
      "Epoch  4, Batch 67: \n",
      "Training Loss: 0.5298, Validation Loss: 0.5382, Validation Accuracy: 73.16%\n",
      "Epoch  4, Batch 68: \n",
      "Training Loss: 0.5122, Validation Loss: 0.5395, Validation Accuracy: 72.36%\n",
      "Epoch  4, Batch 69: \n",
      "Training Loss: 0.4799, Validation Loss: 0.5430, Validation Accuracy: 71.84%\n",
      "Epoch  4, Batch 70: \n",
      "Training Loss: 0.5146, Validation Loss: 0.5362, Validation Accuracy: 73.00%\n",
      "Epoch  4, Batch 71: \n",
      "Training Loss: 0.5092, Validation Loss: 0.5337, Validation Accuracy: 72.96%\n",
      "Epoch  4, Batch 72: \n",
      "Training Loss: 0.5248, Validation Loss: 0.5327, Validation Accuracy: 73.20%\n",
      "Epoch  4, Batch 73: \n",
      "Training Loss: 0.5124, Validation Loss: 0.5355, Validation Accuracy: 72.72%\n",
      "Epoch  4, Batch 74: \n",
      "Training Loss: 0.4482, Validation Loss: 0.5389, Validation Accuracy: 72.72%\n",
      "Epoch  4, Batch 75: \n",
      "Training Loss: 0.5205, Validation Loss: 0.5366, Validation Accuracy: 72.60%\n",
      "Epoch  4, Batch 76: \n",
      "Training Loss: 0.4888, Validation Loss: 0.5321, Validation Accuracy: 73.00%\n",
      "Epoch  4, Batch 77: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4754, Validation Loss: 0.5330, Validation Accuracy: 72.56%\n",
      "Epoch  4, Batch 78: \n",
      "Training Loss: 0.4699, Validation Loss: 0.5321, Validation Accuracy: 72.76%\n",
      "Epoch  4, Batch 79: \n",
      "Training Loss: 0.4840, Validation Loss: 0.5344, Validation Accuracy: 72.24%\n",
      "Epoch  4, Batch 80: \n",
      "Training Loss: 0.4387, Validation Loss: 0.5423, Validation Accuracy: 72.56%\n",
      "Epoch  4, Batch 81: \n",
      "Training Loss: 0.4425, Validation Loss: 0.5387, Validation Accuracy: 72.24%\n",
      "Epoch  4, Batch 82: \n",
      "Training Loss: 0.4715, Validation Loss: 0.5313, Validation Accuracy: 72.52%\n",
      "Epoch  4, Batch 83: \n",
      "Training Loss: 0.5241, Validation Loss: 0.5408, Validation Accuracy: 72.00%\n",
      "Epoch  4, Batch 84: \n",
      "Training Loss: 0.5223, Validation Loss: 0.5381, Validation Accuracy: 72.48%\n",
      "Epoch  4, Batch 85: \n",
      "Training Loss: 0.4837, Validation Loss: 0.5324, Validation Accuracy: 72.68%\n",
      "Epoch  4, Batch 86: \n",
      "Training Loss: 0.4575, Validation Loss: 0.5348, Validation Accuracy: 72.24%\n",
      "Epoch  4, Batch 87: \n",
      "Training Loss: 0.4933, Validation Loss: 0.5379, Validation Accuracy: 72.24%\n",
      "Epoch  4, Batch 88: \n",
      "Training Loss: 0.4920, Validation Loss: 0.5376, Validation Accuracy: 72.48%\n",
      "Epoch  5, Batch 1: \n",
      "Training Loss: 0.5150, Validation Loss: 0.5370, Validation Accuracy: 72.72%\n",
      "Epoch  5, Batch 2: \n",
      "Training Loss: 0.4710, Validation Loss: 0.5375, Validation Accuracy: 72.68%\n",
      "Epoch  5, Batch 3: \n",
      "Training Loss: 0.5000, Validation Loss: 0.5401, Validation Accuracy: 72.40%\n",
      "Epoch  5, Batch 4: \n",
      "Training Loss: 0.5086, Validation Loss: 0.5368, Validation Accuracy: 72.36%\n",
      "Epoch  5, Batch 5: \n",
      "Training Loss: 0.4505, Validation Loss: 0.5303, Validation Accuracy: 72.72%\n",
      "Epoch  5, Batch 6: \n",
      "Training Loss: 0.5202, Validation Loss: 0.5377, Validation Accuracy: 72.28%\n",
      "Epoch  5, Batch 7: \n",
      "Training Loss: 0.5073, Validation Loss: 0.5421, Validation Accuracy: 72.52%\n",
      "Epoch  5, Batch 8: \n",
      "Training Loss: 0.4843, Validation Loss: 0.5360, Validation Accuracy: 72.68%\n",
      "Epoch  5, Batch 9: \n",
      "Training Loss: 0.5161, Validation Loss: 0.5313, Validation Accuracy: 72.92%\n",
      "Epoch  5, Batch 10: \n",
      "Training Loss: 0.5014, Validation Loss: 0.5397, Validation Accuracy: 72.08%\n",
      "Epoch  5, Batch 11: \n",
      "Training Loss: 0.4818, Validation Loss: 0.5514, Validation Accuracy: 71.08%\n",
      "Epoch  5, Batch 12: \n",
      "Training Loss: 0.5416, Validation Loss: 0.5402, Validation Accuracy: 72.00%\n",
      "Epoch  5, Batch 13: \n",
      "Training Loss: 0.5180, Validation Loss: 0.5318, Validation Accuracy: 72.48%\n",
      "Epoch  5, Batch 14: \n",
      "Training Loss: 0.4904, Validation Loss: 0.5353, Validation Accuracy: 72.64%\n",
      "Epoch  5, Batch 15: \n",
      "Training Loss: 0.4996, Validation Loss: 0.5341, Validation Accuracy: 72.72%\n",
      "Epoch  5, Batch 16: \n",
      "Training Loss: 0.5193, Validation Loss: 0.5345, Validation Accuracy: 72.72%\n",
      "Epoch  5, Batch 17: \n",
      "Training Loss: 0.4928, Validation Loss: 0.5361, Validation Accuracy: 72.56%\n",
      "Epoch  5, Batch 18: \n",
      "Training Loss: 0.5339, Validation Loss: 0.5362, Validation Accuracy: 72.56%\n",
      "Epoch  5, Batch 19: \n",
      "Training Loss: 0.4802, Validation Loss: 0.5350, Validation Accuracy: 72.68%\n",
      "Epoch  5, Batch 20: \n",
      "Training Loss: 0.5150, Validation Loss: 0.5345, Validation Accuracy: 72.52%\n",
      "Epoch  5, Batch 21: \n",
      "Training Loss: 0.5190, Validation Loss: 0.5351, Validation Accuracy: 73.00%\n",
      "Epoch  5, Batch 22: \n",
      "Training Loss: 0.5428, Validation Loss: 0.5353, Validation Accuracy: 73.16%\n",
      "Epoch  5, Batch 23: \n",
      "Training Loss: 0.4634, Validation Loss: 0.5338, Validation Accuracy: 73.32%\n",
      "Epoch  5, Batch 24: \n",
      "Training Loss: 0.4439, Validation Loss: 0.5310, Validation Accuracy: 72.84%\n",
      "Epoch  5, Batch 25: \n",
      "Training Loss: 0.4784, Validation Loss: 0.5297, Validation Accuracy: 73.12%\n",
      "Epoch  5, Batch 26: \n",
      "Training Loss: 0.5032, Validation Loss: 0.5297, Validation Accuracy: 72.64%\n",
      "Epoch  5, Batch 27: \n",
      "Training Loss: 0.5101, Validation Loss: 0.5319, Validation Accuracy: 72.56%\n",
      "Epoch  5, Batch 28: \n",
      "Training Loss: 0.4985, Validation Loss: 0.5319, Validation Accuracy: 72.76%\n",
      "Epoch  5, Batch 29: \n",
      "Training Loss: 0.4905, Validation Loss: 0.5256, Validation Accuracy: 72.84%\n",
      "Epoch  5, Batch 30: \n",
      "Training Loss: 0.4674, Validation Loss: 0.5262, Validation Accuracy: 72.96%\n",
      "Epoch  5, Batch 31: \n",
      "Training Loss: 0.4586, Validation Loss: 0.5371, Validation Accuracy: 72.56%\n",
      "Epoch  5, Batch 32: \n",
      "Training Loss: 0.4895, Validation Loss: 0.5384, Validation Accuracy: 72.40%\n",
      "Epoch  5, Batch 33: \n",
      "Training Loss: 0.5057, Validation Loss: 0.5344, Validation Accuracy: 72.96%\n",
      "Epoch  5, Batch 34: \n",
      "Training Loss: 0.5571, Validation Loss: 0.5328, Validation Accuracy: 73.04%\n",
      "Epoch  5, Batch 35: \n",
      "Training Loss: 0.4837, Validation Loss: 0.5282, Validation Accuracy: 73.36%\n",
      "Epoch  5, Batch 36: \n",
      "Training Loss: 0.4892, Validation Loss: 0.5274, Validation Accuracy: 73.16%\n",
      "Epoch  5, Batch 37: \n",
      "Training Loss: 0.4914, Validation Loss: 0.5244, Validation Accuracy: 73.56%\n",
      "Epoch  5, Batch 38: \n",
      "Training Loss: 0.4594, Validation Loss: 0.5232, Validation Accuracy: 73.64%\n",
      "Epoch  5, Batch 39: \n",
      "Training Loss: 0.5058, Validation Loss: 0.5232, Validation Accuracy: 73.36%\n",
      "Epoch  5, Batch 40: \n",
      "Training Loss: 0.4574, Validation Loss: 0.5238, Validation Accuracy: 73.32%\n",
      "Epoch  5, Batch 41: \n",
      "Training Loss: 0.5185, Validation Loss: 0.5266, Validation Accuracy: 73.40%\n",
      "Epoch  5, Batch 42: \n",
      "Training Loss: 0.4852, Validation Loss: 0.5328, Validation Accuracy: 73.20%\n",
      "Epoch  5, Batch 43: \n",
      "Training Loss: 0.4672, Validation Loss: 0.5331, Validation Accuracy: 73.68%\n",
      "Epoch  5, Batch 44: \n",
      "Training Loss: 0.4594, Validation Loss: 0.5294, Validation Accuracy: 73.72%\n",
      "Epoch  5, Batch 45: \n",
      "Training Loss: 0.4690, Validation Loss: 0.5311, Validation Accuracy: 72.96%\n",
      "Epoch  5, Batch 46: \n",
      "Training Loss: 0.4718, Validation Loss: 0.5330, Validation Accuracy: 72.56%\n",
      "Epoch  5, Batch 47: \n",
      "Training Loss: 0.4763, Validation Loss: 0.5270, Validation Accuracy: 73.40%\n",
      "Epoch  5, Batch 48: \n",
      "Training Loss: 0.4661, Validation Loss: 0.5270, Validation Accuracy: 73.72%\n",
      "Epoch  5, Batch 49: \n",
      "Training Loss: 0.4823, Validation Loss: 0.5374, Validation Accuracy: 72.60%\n",
      "Epoch  5, Batch 50: \n",
      "Training Loss: 0.4759, Validation Loss: 0.5363, Validation Accuracy: 72.80%\n",
      "Epoch  5, Batch 51: \n",
      "Training Loss: 0.4777, Validation Loss: 0.5287, Validation Accuracy: 73.32%\n",
      "Epoch  5, Batch 52: \n",
      "Training Loss: 0.4542, Validation Loss: 0.5307, Validation Accuracy: 73.48%\n",
      "Epoch  5, Batch 53: \n",
      "Training Loss: 0.4521, Validation Loss: 0.5331, Validation Accuracy: 73.12%\n",
      "Epoch  5, Batch 54: \n",
      "Training Loss: 0.4454, Validation Loss: 0.5300, Validation Accuracy: 73.36%\n",
      "Epoch  5, Batch 55: \n",
      "Training Loss: 0.5070, Validation Loss: 0.5227, Validation Accuracy: 73.36%\n",
      "Epoch  5, Batch 56: \n",
      "Training Loss: 0.4826, Validation Loss: 0.5228, Validation Accuracy: 73.64%\n",
      "Epoch  5, Batch 57: \n",
      "Training Loss: 0.5014, Validation Loss: 0.5264, Validation Accuracy: 73.08%\n",
      "Epoch  5, Batch 58: \n",
      "Training Loss: 0.4287, Validation Loss: 0.5214, Validation Accuracy: 73.52%\n",
      "Epoch  5, Batch 59: \n",
      "Training Loss: 0.4433, Validation Loss: 0.5230, Validation Accuracy: 73.96%\n",
      "Epoch  5, Batch 60: \n",
      "Training Loss: 0.4952, Validation Loss: 0.5214, Validation Accuracy: 73.60%\n",
      "Epoch  5, Batch 61: \n",
      "Training Loss: 0.4519, Validation Loss: 0.5207, Validation Accuracy: 73.68%\n",
      "Epoch  5, Batch 62: \n",
      "Training Loss: 0.4977, Validation Loss: 0.5299, Validation Accuracy: 72.76%\n",
      "Epoch  5, Batch 63: \n",
      "Training Loss: 0.4494, Validation Loss: 0.5369, Validation Accuracy: 72.52%\n",
      "Epoch  5, Batch 64: \n",
      "Training Loss: 0.4597, Validation Loss: 0.5354, Validation Accuracy: 72.76%\n",
      "Epoch  5, Batch 65: \n",
      "Training Loss: 0.4782, Validation Loss: 0.5329, Validation Accuracy: 73.00%\n",
      "Epoch  5, Batch 66: \n",
      "Training Loss: 0.4724, Validation Loss: 0.5294, Validation Accuracy: 73.48%\n",
      "Epoch  5, Batch 67: \n",
      "Training Loss: 0.5033, Validation Loss: 0.5280, Validation Accuracy: 73.60%\n",
      "Epoch  5, Batch 68: \n",
      "Training Loss: 0.4732, Validation Loss: 0.5285, Validation Accuracy: 73.36%\n",
      "Epoch  5, Batch 69: \n",
      "Training Loss: 0.4542, Validation Loss: 0.5294, Validation Accuracy: 73.00%\n",
      "Epoch  5, Batch 70: \n",
      "Training Loss: 0.4855, Validation Loss: 0.5226, Validation Accuracy: 73.56%\n",
      "Epoch  5, Batch 71: \n",
      "Training Loss: 0.4841, Validation Loss: 0.5202, Validation Accuracy: 73.96%\n",
      "Epoch  5, Batch 72: \n",
      "Training Loss: 0.4782, Validation Loss: 0.5188, Validation Accuracy: 73.84%\n",
      "Epoch  5, Batch 73: \n",
      "Training Loss: 0.4899, Validation Loss: 0.5173, Validation Accuracy: 73.80%\n",
      "Epoch  5, Batch 74: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4076, Validation Loss: 0.5178, Validation Accuracy: 74.04%\n",
      "Epoch  5, Batch 75: \n",
      "Training Loss: 0.4803, Validation Loss: 0.5153, Validation Accuracy: 73.60%\n",
      "Epoch  5, Batch 76: \n",
      "Training Loss: 0.4567, Validation Loss: 0.5149, Validation Accuracy: 73.92%\n",
      "Epoch  5, Batch 77: \n",
      "Training Loss: 0.4454, Validation Loss: 0.5158, Validation Accuracy: 73.96%\n",
      "Epoch  5, Batch 78: \n",
      "Training Loss: 0.4353, Validation Loss: 0.5207, Validation Accuracy: 73.60%\n",
      "Epoch  5, Batch 79: \n",
      "Training Loss: 0.4644, Validation Loss: 0.5225, Validation Accuracy: 73.64%\n",
      "Epoch  5, Batch 80: \n",
      "Training Loss: 0.4178, Validation Loss: 0.5198, Validation Accuracy: 73.64%\n",
      "Epoch  5, Batch 81: \n",
      "Training Loss: 0.4179, Validation Loss: 0.5174, Validation Accuracy: 73.84%\n",
      "Epoch  5, Batch 82: \n",
      "Training Loss: 0.4428, Validation Loss: 0.5223, Validation Accuracy: 73.16%\n",
      "Epoch  5, Batch 83: \n",
      "Training Loss: 0.4826, Validation Loss: 0.5219, Validation Accuracy: 73.20%\n",
      "Epoch  5, Batch 84: \n",
      "Training Loss: 0.4855, Validation Loss: 0.5162, Validation Accuracy: 73.92%\n",
      "Epoch  5, Batch 85: \n",
      "Training Loss: 0.4546, Validation Loss: 0.5229, Validation Accuracy: 73.56%\n",
      "Epoch  5, Batch 86: \n",
      "Training Loss: 0.4182, Validation Loss: 0.5182, Validation Accuracy: 73.88%\n",
      "Epoch  5, Batch 87: \n",
      "Training Loss: 0.4486, Validation Loss: 0.5145, Validation Accuracy: 74.08%\n",
      "Epoch  5, Batch 88: \n",
      "Training Loss: 0.4456, Validation Loss: 0.5175, Validation Accuracy: 73.44%\n",
      "Epoch  6, Batch 1: \n",
      "Training Loss: 0.4722, Validation Loss: 0.5214, Validation Accuracy: 73.08%\n",
      "Epoch  6, Batch 2: \n",
      "Training Loss: 0.4155, Validation Loss: 0.5219, Validation Accuracy: 72.76%\n",
      "Epoch  6, Batch 3: \n",
      "Training Loss: 0.4740, Validation Loss: 0.5219, Validation Accuracy: 72.56%\n",
      "Epoch  6, Batch 4: \n",
      "Training Loss: 0.4570, Validation Loss: 0.5165, Validation Accuracy: 73.72%\n",
      "Epoch  6, Batch 5: \n",
      "Training Loss: 0.4020, Validation Loss: 0.5309, Validation Accuracy: 73.08%\n",
      "Epoch  6, Batch 6: \n",
      "Training Loss: 0.4977, Validation Loss: 0.5333, Validation Accuracy: 73.04%\n",
      "Epoch  6, Batch 7: \n",
      "Training Loss: 0.4612, Validation Loss: 0.5187, Validation Accuracy: 73.36%\n",
      "Epoch  6, Batch 8: \n",
      "Training Loss: 0.4373, Validation Loss: 0.5150, Validation Accuracy: 73.48%\n",
      "Epoch  6, Batch 9: \n",
      "Training Loss: 0.4792, Validation Loss: 0.5174, Validation Accuracy: 73.36%\n",
      "Epoch  6, Batch 10: \n",
      "Training Loss: 0.4724, Validation Loss: 0.5237, Validation Accuracy: 72.76%\n",
      "Epoch  6, Batch 11: \n",
      "Training Loss: 0.4417, Validation Loss: 0.5244, Validation Accuracy: 72.80%\n",
      "Epoch  6, Batch 12: \n",
      "Training Loss: 0.5110, Validation Loss: 0.5195, Validation Accuracy: 73.36%\n",
      "Epoch  6, Batch 13: \n",
      "Training Loss: 0.4899, Validation Loss: 0.5137, Validation Accuracy: 73.56%\n",
      "Epoch  6, Batch 14: \n",
      "Training Loss: 0.4627, Validation Loss: 0.5164, Validation Accuracy: 74.00%\n",
      "Epoch  6, Batch 15: \n",
      "Training Loss: 0.4648, Validation Loss: 0.5171, Validation Accuracy: 73.68%\n",
      "Epoch  6, Batch 16: \n",
      "Training Loss: 0.4869, Validation Loss: 0.5164, Validation Accuracy: 73.40%\n",
      "Epoch  6, Batch 17: \n",
      "Training Loss: 0.4551, Validation Loss: 0.5170, Validation Accuracy: 73.20%\n",
      "Epoch  6, Batch 18: \n",
      "Training Loss: 0.5036, Validation Loss: 0.5169, Validation Accuracy: 73.24%\n",
      "Epoch  6, Batch 19: \n",
      "Training Loss: 0.4506, Validation Loss: 0.5163, Validation Accuracy: 73.60%\n",
      "Epoch  6, Batch 20: \n",
      "Training Loss: 0.4838, Validation Loss: 0.5170, Validation Accuracy: 73.64%\n",
      "Epoch  6, Batch 21: \n",
      "Training Loss: 0.4738, Validation Loss: 0.5186, Validation Accuracy: 73.72%\n",
      "Epoch  6, Batch 22: \n",
      "Training Loss: 0.5204, Validation Loss: 0.5177, Validation Accuracy: 73.76%\n",
      "Epoch  6, Batch 23: \n",
      "Training Loss: 0.4179, Validation Loss: 0.5159, Validation Accuracy: 74.08%\n",
      "Epoch  6, Batch 24: \n",
      "Training Loss: 0.4106, Validation Loss: 0.5127, Validation Accuracy: 73.96%\n",
      "Epoch  6, Batch 25: \n",
      "Training Loss: 0.4491, Validation Loss: 0.5135, Validation Accuracy: 74.04%\n",
      "Epoch  6, Batch 26: \n",
      "Training Loss: 0.4747, Validation Loss: 0.5177, Validation Accuracy: 73.52%\n",
      "Epoch  6, Batch 27: \n",
      "Training Loss: 0.4800, Validation Loss: 0.5171, Validation Accuracy: 73.24%\n",
      "Epoch  6, Batch 28: \n",
      "Training Loss: 0.4531, Validation Loss: 0.5126, Validation Accuracy: 73.44%\n",
      "Epoch  6, Batch 29: \n",
      "Training Loss: 0.4475, Validation Loss: 0.5112, Validation Accuracy: 73.80%\n",
      "Epoch  6, Batch 30: \n",
      "Training Loss: 0.4380, Validation Loss: 0.5170, Validation Accuracy: 74.12%\n",
      "Epoch  6, Batch 31: \n",
      "Training Loss: 0.4269, Validation Loss: 0.5287, Validation Accuracy: 73.68%\n",
      "Epoch  6, Batch 32: \n",
      "Training Loss: 0.4394, Validation Loss: 0.5209, Validation Accuracy: 73.60%\n",
      "Epoch  6, Batch 33: \n",
      "Training Loss: 0.4644, Validation Loss: 0.5164, Validation Accuracy: 73.08%\n",
      "Epoch  6, Batch 34: \n",
      "Training Loss: 0.5463, Validation Loss: 0.5187, Validation Accuracy: 73.36%\n",
      "Epoch  6, Batch 35: \n",
      "Training Loss: 0.4538, Validation Loss: 0.5184, Validation Accuracy: 73.08%\n",
      "Epoch  6, Batch 36: \n",
      "Training Loss: 0.4576, Validation Loss: 0.5137, Validation Accuracy: 73.36%\n",
      "Epoch  6, Batch 37: \n",
      "Training Loss: 0.4510, Validation Loss: 0.5139, Validation Accuracy: 73.72%\n",
      "Epoch  6, Batch 38: \n",
      "Training Loss: 0.4452, Validation Loss: 0.5140, Validation Accuracy: 74.08%\n",
      "Epoch  6, Batch 39: \n",
      "Training Loss: 0.4744, Validation Loss: 0.5106, Validation Accuracy: 74.24%\n",
      "Epoch  6, Batch 40: \n",
      "Training Loss: 0.4470, Validation Loss: 0.5151, Validation Accuracy: 72.68%\n",
      "Epoch  6, Batch 41: \n",
      "Training Loss: 0.4911, Validation Loss: 0.5190, Validation Accuracy: 72.76%\n",
      "Epoch  6, Batch 42: \n",
      "Training Loss: 0.4477, Validation Loss: 0.5150, Validation Accuracy: 73.68%\n",
      "Epoch  6, Batch 43: \n",
      "Training Loss: 0.4467, Validation Loss: 0.5270, Validation Accuracy: 73.64%\n",
      "Epoch  6, Batch 44: \n",
      "Training Loss: 0.4400, Validation Loss: 0.5373, Validation Accuracy: 73.00%\n",
      "Epoch  6, Batch 45: \n",
      "Training Loss: 0.4589, Validation Loss: 0.5194, Validation Accuracy: 74.28%\n",
      "Epoch  6, Batch 46: \n",
      "Training Loss: 0.4279, Validation Loss: 0.5099, Validation Accuracy: 73.96%\n",
      "Epoch  6, Batch 47: \n",
      "Training Loss: 0.4551, Validation Loss: 0.5141, Validation Accuracy: 73.92%\n",
      "Epoch  6, Batch 48: \n",
      "Training Loss: 0.4553, Validation Loss: 0.5133, Validation Accuracy: 73.56%\n",
      "Epoch  6, Batch 49: \n",
      "Training Loss: 0.4451, Validation Loss: 0.5078, Validation Accuracy: 74.92%\n",
      "Epoch  6, Batch 50: \n",
      "Training Loss: 0.4260, Validation Loss: 0.5129, Validation Accuracy: 73.88%\n",
      "Epoch  6, Batch 51: \n",
      "Training Loss: 0.4467, Validation Loss: 0.5217, Validation Accuracy: 73.56%\n",
      "Epoch  6, Batch 52: \n",
      "Training Loss: 0.4151, Validation Loss: 0.5193, Validation Accuracy: 73.80%\n",
      "Epoch  6, Batch 53: \n",
      "Training Loss: 0.4108, Validation Loss: 0.5113, Validation Accuracy: 73.96%\n",
      "Epoch  6, Batch 54: \n",
      "Training Loss: 0.4181, Validation Loss: 0.5104, Validation Accuracy: 74.32%\n",
      "Epoch  6, Batch 55: \n",
      "Training Loss: 0.4924, Validation Loss: 0.5108, Validation Accuracy: 74.08%\n",
      "Epoch  6, Batch 56: \n",
      "Training Loss: 0.4469, Validation Loss: 0.5097, Validation Accuracy: 74.04%\n",
      "Epoch  6, Batch 57: \n",
      "Training Loss: 0.4621, Validation Loss: 0.5082, Validation Accuracy: 74.28%\n",
      "Epoch  6, Batch 58: \n",
      "Training Loss: 0.4088, Validation Loss: 0.5088, Validation Accuracy: 74.28%\n",
      "Epoch  6, Batch 59: \n",
      "Training Loss: 0.4237, Validation Loss: 0.5079, Validation Accuracy: 74.40%\n",
      "Epoch  6, Batch 60: \n",
      "Training Loss: 0.4491, Validation Loss: 0.5102, Validation Accuracy: 74.40%\n",
      "Epoch  6, Batch 61: \n",
      "Training Loss: 0.4315, Validation Loss: 0.5129, Validation Accuracy: 74.40%\n",
      "Epoch  6, Batch 62: \n",
      "Training Loss: 0.4744, Validation Loss: 0.5219, Validation Accuracy: 73.80%\n",
      "Epoch  6, Batch 63: \n",
      "Training Loss: 0.4118, Validation Loss: 0.5163, Validation Accuracy: 74.12%\n",
      "Epoch  6, Batch 64: \n",
      "Training Loss: 0.4313, Validation Loss: 0.5099, Validation Accuracy: 74.52%\n",
      "Epoch  6, Batch 65: \n",
      "Training Loss: 0.4567, Validation Loss: 0.5105, Validation Accuracy: 74.40%\n",
      "Epoch  6, Batch 66: \n",
      "Training Loss: 0.4377, Validation Loss: 0.5190, Validation Accuracy: 73.92%\n",
      "Epoch  6, Batch 67: \n",
      "Training Loss: 0.4885, Validation Loss: 0.5169, Validation Accuracy: 74.08%\n",
      "Epoch  6, Batch 68: \n",
      "Training Loss: 0.4286, Validation Loss: 0.5073, Validation Accuracy: 74.08%\n",
      "Epoch  6, Batch 69: \n",
      "Training Loss: 0.4242, Validation Loss: 0.5077, Validation Accuracy: 73.84%\n",
      "Epoch  6, Batch 70: \n",
      "Training Loss: 0.4668, Validation Loss: 0.5113, Validation Accuracy: 73.92%\n",
      "Epoch  6, Batch 71: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4593, Validation Loss: 0.5115, Validation Accuracy: 73.84%\n",
      "Epoch  6, Batch 72: \n",
      "Training Loss: 0.4550, Validation Loss: 0.5072, Validation Accuracy: 73.80%\n",
      "Epoch  6, Batch 73: \n",
      "Training Loss: 0.4693, Validation Loss: 0.5037, Validation Accuracy: 73.92%\n",
      "Epoch  6, Batch 74: \n",
      "Training Loss: 0.3905, Validation Loss: 0.5161, Validation Accuracy: 74.24%\n",
      "Epoch  6, Batch 75: \n",
      "Training Loss: 0.4722, Validation Loss: 0.5184, Validation Accuracy: 73.64%\n",
      "Epoch  6, Batch 76: \n",
      "Training Loss: 0.4422, Validation Loss: 0.5082, Validation Accuracy: 74.44%\n",
      "Epoch  6, Batch 77: \n",
      "Training Loss: 0.4201, Validation Loss: 0.5085, Validation Accuracy: 74.16%\n",
      "Epoch  6, Batch 78: \n",
      "Training Loss: 0.4221, Validation Loss: 0.5141, Validation Accuracy: 73.80%\n",
      "Epoch  6, Batch 79: \n",
      "Training Loss: 0.4412, Validation Loss: 0.5124, Validation Accuracy: 73.80%\n",
      "Epoch  6, Batch 80: \n",
      "Training Loss: 0.3757, Validation Loss: 0.5115, Validation Accuracy: 74.32%\n",
      "Epoch  6, Batch 81: \n",
      "Training Loss: 0.4032, Validation Loss: 0.5262, Validation Accuracy: 73.72%\n",
      "Epoch  6, Batch 82: \n",
      "Training Loss: 0.4129, Validation Loss: 0.5214, Validation Accuracy: 73.68%\n",
      "Epoch  6, Batch 83: \n",
      "Training Loss: 0.4462, Validation Loss: 0.5114, Validation Accuracy: 74.48%\n",
      "Epoch  6, Batch 84: \n",
      "Training Loss: 0.4619, Validation Loss: 0.5121, Validation Accuracy: 74.08%\n",
      "Epoch  6, Batch 85: \n",
      "Training Loss: 0.4399, Validation Loss: 0.5141, Validation Accuracy: 73.84%\n",
      "Epoch  6, Batch 86: \n",
      "Training Loss: 0.3855, Validation Loss: 0.5164, Validation Accuracy: 73.72%\n",
      "Epoch  6, Batch 87: \n",
      "Training Loss: 0.4270, Validation Loss: 0.5115, Validation Accuracy: 74.24%\n",
      "Epoch  6, Batch 88: \n",
      "Training Loss: 0.4246, Validation Loss: 0.5151, Validation Accuracy: 73.72%\n",
      "Epoch  7, Batch 1: \n",
      "Training Loss: 0.4556, Validation Loss: 0.5162, Validation Accuracy: 73.60%\n",
      "Epoch  7, Batch 2: \n",
      "Training Loss: 0.3966, Validation Loss: 0.5080, Validation Accuracy: 74.52%\n",
      "Epoch  7, Batch 3: \n",
      "Training Loss: 0.4455, Validation Loss: 0.5081, Validation Accuracy: 73.64%\n",
      "Epoch  7, Batch 4: \n",
      "Training Loss: 0.4313, Validation Loss: 0.5134, Validation Accuracy: 73.76%\n",
      "Epoch  7, Batch 5: \n",
      "Training Loss: 0.3606, Validation Loss: 0.5066, Validation Accuracy: 73.52%\n",
      "Epoch  7, Batch 6: \n",
      "Training Loss: 0.4644, Validation Loss: 0.5148, Validation Accuracy: 74.00%\n",
      "Epoch  7, Batch 7: \n",
      "Training Loss: 0.4489, Validation Loss: 0.5191, Validation Accuracy: 74.24%\n",
      "Epoch  7, Batch 8: \n",
      "Training Loss: 0.4185, Validation Loss: 0.5140, Validation Accuracy: 74.20%\n",
      "Epoch  7, Batch 9: \n",
      "Training Loss: 0.4638, Validation Loss: 0.5028, Validation Accuracy: 74.48%\n",
      "Epoch  7, Batch 10: \n",
      "Training Loss: 0.4467, Validation Loss: 0.5043, Validation Accuracy: 74.24%\n",
      "Epoch  7, Batch 11: \n",
      "Training Loss: 0.4345, Validation Loss: 0.5151, Validation Accuracy: 73.92%\n",
      "Epoch  7, Batch 12: \n",
      "Training Loss: 0.5097, Validation Loss: 0.5190, Validation Accuracy: 73.68%\n",
      "Epoch  7, Batch 13: \n",
      "Training Loss: 0.4788, Validation Loss: 0.5085, Validation Accuracy: 74.44%\n",
      "Epoch  7, Batch 14: \n",
      "Training Loss: 0.4421, Validation Loss: 0.5019, Validation Accuracy: 74.92%\n",
      "Epoch  7, Batch 15: \n",
      "Training Loss: 0.4482, Validation Loss: 0.5056, Validation Accuracy: 74.20%\n",
      "Epoch  7, Batch 16: \n",
      "Training Loss: 0.4653, Validation Loss: 0.5067, Validation Accuracy: 73.96%\n",
      "Epoch  7, Batch 17: \n",
      "Training Loss: 0.4337, Validation Loss: 0.5051, Validation Accuracy: 74.48%\n",
      "Epoch  7, Batch 18: \n",
      "Training Loss: 0.4751, Validation Loss: 0.5054, Validation Accuracy: 74.76%\n",
      "Epoch  7, Batch 19: \n",
      "Training Loss: 0.4257, Validation Loss: 0.5067, Validation Accuracy: 74.44%\n",
      "Epoch  7, Batch 20: \n",
      "Training Loss: 0.4614, Validation Loss: 0.5077, Validation Accuracy: 74.36%\n",
      "Epoch  7, Batch 21: \n",
      "Training Loss: 0.4455, Validation Loss: 0.5071, Validation Accuracy: 74.36%\n",
      "Epoch  7, Batch 22: \n",
      "Training Loss: 0.4920, Validation Loss: 0.5062, Validation Accuracy: 74.24%\n",
      "Epoch  7, Batch 23: \n",
      "Training Loss: 0.4009, Validation Loss: 0.5061, Validation Accuracy: 74.12%\n",
      "Epoch  7, Batch 24: \n",
      "Training Loss: 0.3887, Validation Loss: 0.5066, Validation Accuracy: 74.28%\n",
      "Epoch  7, Batch 25: \n",
      "Training Loss: 0.4304, Validation Loss: 0.5101, Validation Accuracy: 73.88%\n",
      "Epoch  7, Batch 26: \n",
      "Training Loss: 0.4694, Validation Loss: 0.5085, Validation Accuracy: 74.00%\n",
      "Epoch  7, Batch 27: \n",
      "Training Loss: 0.4540, Validation Loss: 0.5011, Validation Accuracy: 74.08%\n",
      "Epoch  7, Batch 28: \n",
      "Training Loss: 0.4306, Validation Loss: 0.5046, Validation Accuracy: 74.04%\n",
      "Epoch  7, Batch 29: \n",
      "Training Loss: 0.4317, Validation Loss: 0.5093, Validation Accuracy: 74.08%\n",
      "Epoch  7, Batch 30: \n",
      "Training Loss: 0.4125, Validation Loss: 0.5009, Validation Accuracy: 73.68%\n",
      "Epoch  7, Batch 31: \n",
      "Training Loss: 0.4015, Validation Loss: 0.5062, Validation Accuracy: 74.72%\n",
      "Epoch  7, Batch 32: \n",
      "Training Loss: 0.4195, Validation Loss: 0.5193, Validation Accuracy: 74.08%\n",
      "Epoch  7, Batch 33: \n",
      "Training Loss: 0.4444, Validation Loss: 0.5251, Validation Accuracy: 74.04%\n",
      "Epoch  7, Batch 34: \n",
      "Training Loss: 0.5065, Validation Loss: 0.5189, Validation Accuracy: 74.24%\n",
      "Epoch  7, Batch 35: \n",
      "Training Loss: 0.4382, Validation Loss: 0.5015, Validation Accuracy: 74.56%\n",
      "Epoch  7, Batch 36: \n",
      "Training Loss: 0.4385, Validation Loss: 0.5017, Validation Accuracy: 74.52%\n",
      "Epoch  7, Batch 37: \n",
      "Training Loss: 0.4246, Validation Loss: 0.5063, Validation Accuracy: 74.16%\n",
      "Epoch  7, Batch 38: \n",
      "Training Loss: 0.4235, Validation Loss: 0.5094, Validation Accuracy: 74.36%\n",
      "Epoch  7, Batch 39: \n",
      "Training Loss: 0.4649, Validation Loss: 0.5060, Validation Accuracy: 74.24%\n",
      "Epoch  7, Batch 40: \n",
      "Training Loss: 0.4224, Validation Loss: 0.5014, Validation Accuracy: 74.84%\n",
      "Epoch  7, Batch 41: \n",
      "Training Loss: 0.4598, Validation Loss: 0.5045, Validation Accuracy: 75.20%\n",
      "Epoch  7, Batch 42: \n",
      "Training Loss: 0.4389, Validation Loss: 0.5210, Validation Accuracy: 73.84%\n",
      "Epoch  7, Batch 43: \n",
      "Training Loss: 0.4300, Validation Loss: 0.5275, Validation Accuracy: 73.16%\n",
      "Epoch  7, Batch 44: \n",
      "Training Loss: 0.4080, Validation Loss: 0.5143, Validation Accuracy: 74.12%\n",
      "Epoch  7, Batch 45: \n",
      "Training Loss: 0.4252, Validation Loss: 0.5024, Validation Accuracy: 75.20%\n",
      "Epoch  7, Batch 46: \n",
      "Training Loss: 0.4145, Validation Loss: 0.5130, Validation Accuracy: 74.12%\n",
      "Epoch  7, Batch 47: \n",
      "Training Loss: 0.4429, Validation Loss: 0.5141, Validation Accuracy: 73.96%\n",
      "Epoch  7, Batch 48: \n",
      "Training Loss: 0.4283, Validation Loss: 0.5019, Validation Accuracy: 75.04%\n",
      "Epoch  7, Batch 49: \n",
      "Training Loss: 0.4258, Validation Loss: 0.5048, Validation Accuracy: 74.80%\n",
      "Epoch  7, Batch 50: \n",
      "Training Loss: 0.4168, Validation Loss: 0.5182, Validation Accuracy: 73.44%\n",
      "Epoch  7, Batch 51: \n",
      "Training Loss: 0.4470, Validation Loss: 0.5190, Validation Accuracy: 73.60%\n",
      "Epoch  7, Batch 52: \n",
      "Training Loss: 0.3941, Validation Loss: 0.5131, Validation Accuracy: 73.56%\n",
      "Epoch  7, Batch 53: \n",
      "Training Loss: 0.3868, Validation Loss: 0.5068, Validation Accuracy: 74.84%\n",
      "Epoch  7, Batch 54: \n",
      "Training Loss: 0.3786, Validation Loss: 0.5059, Validation Accuracy: 74.60%\n",
      "Epoch  7, Batch 55: \n",
      "Training Loss: 0.4623, Validation Loss: 0.5039, Validation Accuracy: 73.92%\n",
      "Epoch  7, Batch 56: \n",
      "Training Loss: 0.4171, Validation Loss: 0.5027, Validation Accuracy: 73.88%\n",
      "Epoch  7, Batch 57: \n",
      "Training Loss: 0.4293, Validation Loss: 0.5010, Validation Accuracy: 74.40%\n",
      "Epoch  7, Batch 58: \n",
      "Training Loss: 0.3699, Validation Loss: 0.5009, Validation Accuracy: 74.40%\n",
      "Epoch  7, Batch 59: \n",
      "Training Loss: 0.3966, Validation Loss: 0.5010, Validation Accuracy: 74.44%\n",
      "Epoch  7, Batch 60: \n",
      "Training Loss: 0.4273, Validation Loss: 0.5044, Validation Accuracy: 74.32%\n",
      "Epoch  7, Batch 61: \n",
      "Training Loss: 0.4014, Validation Loss: 0.5042, Validation Accuracy: 74.64%\n",
      "Epoch  7, Batch 62: \n",
      "Training Loss: 0.4598, Validation Loss: 0.5086, Validation Accuracy: 74.64%\n",
      "Epoch  7, Batch 63: \n",
      "Training Loss: 0.3895, Validation Loss: 0.5066, Validation Accuracy: 74.84%\n",
      "Epoch  7, Batch 64: \n",
      "Training Loss: 0.3957, Validation Loss: 0.5019, Validation Accuracy: 74.96%\n",
      "Epoch  7, Batch 65: \n",
      "Training Loss: 0.4230, Validation Loss: 0.5046, Validation Accuracy: 74.80%\n",
      "Epoch  7, Batch 66: \n",
      "Training Loss: 0.4185, Validation Loss: 0.5106, Validation Accuracy: 74.20%\n",
      "Epoch  7, Batch 67: \n",
      "Training Loss: 0.4601, Validation Loss: 0.5090, Validation Accuracy: 74.52%\n",
      "Epoch  7, Batch 68: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4132, Validation Loss: 0.5044, Validation Accuracy: 74.88%\n",
      "Epoch  7, Batch 69: \n",
      "Training Loss: 0.4019, Validation Loss: 0.5022, Validation Accuracy: 75.00%\n",
      "Epoch  7, Batch 70: \n",
      "Training Loss: 0.4387, Validation Loss: 0.5008, Validation Accuracy: 74.56%\n",
      "Epoch  7, Batch 71: \n",
      "Training Loss: 0.4259, Validation Loss: 0.5026, Validation Accuracy: 74.80%\n",
      "Epoch  7, Batch 72: \n",
      "Training Loss: 0.4280, Validation Loss: 0.5013, Validation Accuracy: 74.76%\n",
      "Epoch  7, Batch 73: \n",
      "Training Loss: 0.4617, Validation Loss: 0.4963, Validation Accuracy: 75.00%\n",
      "Epoch  7, Batch 74: \n",
      "Training Loss: 0.3541, Validation Loss: 0.4982, Validation Accuracy: 75.00%\n",
      "Epoch  7, Batch 75: \n",
      "Training Loss: 0.4489, Validation Loss: 0.5027, Validation Accuracy: 74.64%\n",
      "Epoch  7, Batch 76: \n",
      "Training Loss: 0.4278, Validation Loss: 0.5003, Validation Accuracy: 75.08%\n",
      "Epoch  7, Batch 77: \n",
      "Training Loss: 0.3882, Validation Loss: 0.4972, Validation Accuracy: 74.76%\n",
      "Epoch  7, Batch 78: \n",
      "Training Loss: 0.3813, Validation Loss: 0.4991, Validation Accuracy: 74.44%\n",
      "Epoch  7, Batch 79: \n",
      "Training Loss: 0.4189, Validation Loss: 0.5002, Validation Accuracy: 74.80%\n",
      "Epoch  7, Batch 80: \n",
      "Training Loss: 0.3681, Validation Loss: 0.5022, Validation Accuracy: 74.44%\n",
      "Epoch  7, Batch 81: \n",
      "Training Loss: 0.3672, Validation Loss: 0.5018, Validation Accuracy: 74.84%\n",
      "Epoch  7, Batch 82: \n",
      "Training Loss: 0.3925, Validation Loss: 0.5014, Validation Accuracy: 74.40%\n",
      "Epoch  7, Batch 83: \n",
      "Training Loss: 0.4101, Validation Loss: 0.5024, Validation Accuracy: 74.08%\n",
      "Epoch  7, Batch 84: \n",
      "Training Loss: 0.4455, Validation Loss: 0.5005, Validation Accuracy: 74.88%\n",
      "Epoch  7, Batch 85: \n",
      "Training Loss: 0.4037, Validation Loss: 0.4997, Validation Accuracy: 74.88%\n",
      "Epoch  7, Batch 86: \n",
      "Training Loss: 0.3597, Validation Loss: 0.4992, Validation Accuracy: 74.96%\n",
      "Epoch  7, Batch 87: \n",
      "Training Loss: 0.3986, Validation Loss: 0.4990, Validation Accuracy: 74.68%\n",
      "Epoch  7, Batch 88: \n",
      "Training Loss: 0.3899, Validation Loss: 0.5009, Validation Accuracy: 74.64%\n",
      "Epoch  8, Batch 1: \n",
      "Training Loss: 0.4179, Validation Loss: 0.5036, Validation Accuracy: 74.60%\n",
      "Epoch  8, Batch 2: \n",
      "Training Loss: 0.3754, Validation Loss: 0.5022, Validation Accuracy: 74.40%\n",
      "Epoch  8, Batch 3: \n",
      "Training Loss: 0.4299, Validation Loss: 0.5030, Validation Accuracy: 74.32%\n",
      "Epoch  8, Batch 4: \n",
      "Training Loss: 0.4009, Validation Loss: 0.4985, Validation Accuracy: 75.12%\n",
      "Epoch  8, Batch 5: \n",
      "Training Loss: 0.3384, Validation Loss: 0.4976, Validation Accuracy: 75.08%\n",
      "Epoch  8, Batch 6: \n",
      "Training Loss: 0.4433, Validation Loss: 0.5007, Validation Accuracy: 74.88%\n",
      "Epoch  8, Batch 7: \n",
      "Training Loss: 0.4210, Validation Loss: 0.4964, Validation Accuracy: 74.48%\n",
      "Epoch  8, Batch 8: \n",
      "Training Loss: 0.3999, Validation Loss: 0.4976, Validation Accuracy: 74.16%\n",
      "Epoch  8, Batch 9: \n",
      "Training Loss: 0.4402, Validation Loss: 0.4955, Validation Accuracy: 74.52%\n",
      "Epoch  8, Batch 10: \n",
      "Training Loss: 0.4207, Validation Loss: 0.4960, Validation Accuracy: 74.68%\n",
      "Epoch  8, Batch 11: \n",
      "Training Loss: 0.3964, Validation Loss: 0.4994, Validation Accuracy: 74.76%\n",
      "Epoch  8, Batch 12: \n",
      "Training Loss: 0.4597, Validation Loss: 0.4986, Validation Accuracy: 74.56%\n",
      "Epoch  8, Batch 13: \n",
      "Training Loss: 0.4650, Validation Loss: 0.4997, Validation Accuracy: 74.52%\n",
      "Epoch  8, Batch 14: \n",
      "Training Loss: 0.4226, Validation Loss: 0.4978, Validation Accuracy: 74.96%\n",
      "Epoch  8, Batch 15: \n",
      "Training Loss: 0.4171, Validation Loss: 0.4984, Validation Accuracy: 74.72%\n",
      "Epoch  8, Batch 16: \n",
      "Training Loss: 0.4383, Validation Loss: 0.4989, Validation Accuracy: 74.40%\n",
      "Epoch  8, Batch 17: \n",
      "Training Loss: 0.4019, Validation Loss: 0.4993, Validation Accuracy: 74.72%\n",
      "Epoch  8, Batch 18: \n",
      "Training Loss: 0.4523, Validation Loss: 0.4996, Validation Accuracy: 74.68%\n",
      "Epoch  8, Batch 19: \n",
      "Training Loss: 0.4037, Validation Loss: 0.5005, Validation Accuracy: 74.68%\n",
      "Epoch  8, Batch 20: \n",
      "Training Loss: 0.4350, Validation Loss: 0.5018, Validation Accuracy: 74.56%\n",
      "Epoch  8, Batch 21: \n",
      "Training Loss: 0.4251, Validation Loss: 0.4999, Validation Accuracy: 74.68%\n",
      "Epoch  8, Batch 22: \n",
      "Training Loss: 0.4608, Validation Loss: 0.4983, Validation Accuracy: 74.76%\n",
      "Epoch  8, Batch 23: \n",
      "Training Loss: 0.3735, Validation Loss: 0.4957, Validation Accuracy: 75.32%\n",
      "Epoch  8, Batch 24: \n",
      "Training Loss: 0.3693, Validation Loss: 0.4940, Validation Accuracy: 75.36%\n",
      "Epoch  8, Batch 25: \n",
      "Training Loss: 0.4144, Validation Loss: 0.4940, Validation Accuracy: 74.52%\n",
      "Epoch  8, Batch 26: \n",
      "Training Loss: 0.4323, Validation Loss: 0.4943, Validation Accuracy: 74.64%\n",
      "Epoch  8, Batch 27: \n",
      "Training Loss: 0.4400, Validation Loss: 0.4927, Validation Accuracy: 75.00%\n",
      "Epoch  8, Batch 28: \n",
      "Training Loss: 0.4127, Validation Loss: 0.4915, Validation Accuracy: 74.84%\n",
      "Epoch  8, Batch 29: \n",
      "Training Loss: 0.4078, Validation Loss: 0.4921, Validation Accuracy: 75.00%\n",
      "Epoch  8, Batch 30: \n",
      "Training Loss: 0.3880, Validation Loss: 0.4907, Validation Accuracy: 74.76%\n",
      "Epoch  8, Batch 31: \n",
      "Training Loss: 0.3775, Validation Loss: 0.4932, Validation Accuracy: 75.20%\n",
      "Epoch  8, Batch 32: \n",
      "Training Loss: 0.3751, Validation Loss: 0.5017, Validation Accuracy: 74.68%\n",
      "Epoch  8, Batch 33: \n",
      "Training Loss: 0.4034, Validation Loss: 0.5104, Validation Accuracy: 74.72%\n",
      "Epoch  8, Batch 34: \n",
      "Training Loss: 0.4918, Validation Loss: 0.5172, Validation Accuracy: 74.12%\n",
      "Epoch  8, Batch 35: \n",
      "Training Loss: 0.4025, Validation Loss: 0.5030, Validation Accuracy: 75.28%\n",
      "Epoch  8, Batch 36: \n",
      "Training Loss: 0.4097, Validation Loss: 0.4974, Validation Accuracy: 75.36%\n",
      "Epoch  8, Batch 37: \n",
      "Training Loss: 0.3837, Validation Loss: 0.4964, Validation Accuracy: 75.48%\n",
      "Epoch  8, Batch 38: \n",
      "Training Loss: 0.3920, Validation Loss: 0.5006, Validation Accuracy: 75.12%\n",
      "Epoch  8, Batch 39: \n",
      "Training Loss: 0.4357, Validation Loss: 0.5000, Validation Accuracy: 74.84%\n",
      "Epoch  8, Batch 40: \n",
      "Training Loss: 0.4030, Validation Loss: 0.4980, Validation Accuracy: 74.80%\n",
      "Epoch  8, Batch 41: \n",
      "Training Loss: 0.4364, Validation Loss: 0.5056, Validation Accuracy: 74.84%\n",
      "Epoch  8, Batch 42: \n",
      "Training Loss: 0.4204, Validation Loss: 0.5274, Validation Accuracy: 73.36%\n",
      "Epoch  8, Batch 43: \n",
      "Training Loss: 0.4259, Validation Loss: 0.5236, Validation Accuracy: 73.56%\n",
      "Epoch  8, Batch 44: \n",
      "Training Loss: 0.3870, Validation Loss: 0.5082, Validation Accuracy: 75.24%\n",
      "Epoch  8, Batch 45: \n",
      "Training Loss: 0.4029, Validation Loss: 0.5015, Validation Accuracy: 74.72%\n",
      "Epoch  8, Batch 46: \n",
      "Training Loss: 0.4058, Validation Loss: 0.5134, Validation Accuracy: 73.64%\n",
      "Epoch  8, Batch 47: \n",
      "Training Loss: 0.4294, Validation Loss: 0.5110, Validation Accuracy: 74.24%\n",
      "Epoch  8, Batch 48: \n",
      "Training Loss: 0.4172, Validation Loss: 0.4948, Validation Accuracy: 75.32%\n",
      "Epoch  8, Batch 49: \n",
      "Training Loss: 0.4091, Validation Loss: 0.5041, Validation Accuracy: 74.68%\n",
      "Epoch  8, Batch 50: \n",
      "Training Loss: 0.3994, Validation Loss: 0.5171, Validation Accuracy: 73.84%\n",
      "Epoch  8, Batch 51: \n",
      "Training Loss: 0.4233, Validation Loss: 0.5097, Validation Accuracy: 74.52%\n",
      "Epoch  8, Batch 52: \n",
      "Training Loss: 0.3637, Validation Loss: 0.4974, Validation Accuracy: 75.36%\n",
      "Epoch  8, Batch 53: \n",
      "Training Loss: 0.3673, Validation Loss: 0.4977, Validation Accuracy: 75.00%\n",
      "Epoch  8, Batch 54: \n",
      "Training Loss: 0.3710, Validation Loss: 0.5030, Validation Accuracy: 74.80%\n",
      "Epoch  8, Batch 55: \n",
      "Training Loss: 0.4497, Validation Loss: 0.5013, Validation Accuracy: 75.08%\n",
      "Epoch  8, Batch 56: \n",
      "Training Loss: 0.4033, Validation Loss: 0.5006, Validation Accuracy: 75.64%\n",
      "Epoch  8, Batch 57: \n",
      "Training Loss: 0.4099, Validation Loss: 0.5028, Validation Accuracy: 75.12%\n",
      "Epoch  8, Batch 58: \n",
      "Training Loss: 0.3696, Validation Loss: 0.5079, Validation Accuracy: 75.40%\n",
      "Epoch  8, Batch 59: \n",
      "Training Loss: 0.3790, Validation Loss: 0.5072, Validation Accuracy: 75.44%\n",
      "Epoch  8, Batch 60: \n",
      "Training Loss: 0.4020, Validation Loss: 0.5082, Validation Accuracy: 74.92%\n",
      "Epoch  8, Batch 61: \n",
      "Training Loss: 0.3915, Validation Loss: 0.5057, Validation Accuracy: 75.08%\n",
      "Epoch  8, Batch 62: \n",
      "Training Loss: 0.4386, Validation Loss: 0.5049, Validation Accuracy: 75.32%\n",
      "Epoch  8, Batch 63: \n",
      "Training Loss: 0.3623, Validation Loss: 0.5032, Validation Accuracy: 75.40%\n",
      "Epoch  8, Batch 64: \n",
      "Training Loss: 0.3700, Validation Loss: 0.5012, Validation Accuracy: 75.40%\n",
      "Epoch  8, Batch 65: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3907, Validation Loss: 0.5072, Validation Accuracy: 75.00%\n",
      "Epoch  8, Batch 66: \n",
      "Training Loss: 0.3885, Validation Loss: 0.5203, Validation Accuracy: 74.44%\n",
      "Epoch  8, Batch 67: \n",
      "Training Loss: 0.4464, Validation Loss: 0.5116, Validation Accuracy: 74.68%\n",
      "Epoch  8, Batch 68: \n",
      "Training Loss: 0.3694, Validation Loss: 0.4972, Validation Accuracy: 75.16%\n",
      "Epoch  8, Batch 69: \n",
      "Training Loss: 0.3922, Validation Loss: 0.5036, Validation Accuracy: 74.84%\n",
      "Epoch  8, Batch 70: \n",
      "Training Loss: 0.4448, Validation Loss: 0.5099, Validation Accuracy: 74.68%\n",
      "Epoch  8, Batch 71: \n",
      "Training Loss: 0.4189, Validation Loss: 0.5141, Validation Accuracy: 74.68%\n",
      "Epoch  8, Batch 72: \n",
      "Training Loss: 0.4124, Validation Loss: 0.5044, Validation Accuracy: 75.12%\n",
      "Epoch  8, Batch 73: \n",
      "Training Loss: 0.4392, Validation Loss: 0.4944, Validation Accuracy: 74.92%\n",
      "Epoch  8, Batch 74: \n",
      "Training Loss: 0.3519, Validation Loss: 0.4950, Validation Accuracy: 75.24%\n",
      "Epoch  8, Batch 75: \n",
      "Training Loss: 0.4326, Validation Loss: 0.5068, Validation Accuracy: 74.12%\n",
      "Epoch  8, Batch 76: \n",
      "Training Loss: 0.4191, Validation Loss: 0.5132, Validation Accuracy: 73.68%\n",
      "Epoch  8, Batch 77: \n",
      "Training Loss: 0.3921, Validation Loss: 0.5082, Validation Accuracy: 74.08%\n",
      "Epoch  8, Batch 78: \n",
      "Training Loss: 0.3731, Validation Loss: 0.5003, Validation Accuracy: 74.72%\n",
      "Epoch  8, Batch 79: \n",
      "Training Loss: 0.4106, Validation Loss: 0.4949, Validation Accuracy: 75.12%\n",
      "Epoch  8, Batch 80: \n",
      "Training Loss: 0.3592, Validation Loss: 0.4978, Validation Accuracy: 75.60%\n",
      "Epoch  8, Batch 81: \n",
      "Training Loss: 0.3447, Validation Loss: 0.5019, Validation Accuracy: 75.16%\n",
      "Epoch  8, Batch 82: \n",
      "Training Loss: 0.3598, Validation Loss: 0.5012, Validation Accuracy: 75.28%\n",
      "Epoch  8, Batch 83: \n",
      "Training Loss: 0.3832, Validation Loss: 0.5075, Validation Accuracy: 74.92%\n",
      "Epoch  8, Batch 84: \n",
      "Training Loss: 0.4290, Validation Loss: 0.5131, Validation Accuracy: 73.96%\n",
      "Epoch  8, Batch 85: \n",
      "Training Loss: 0.3772, Validation Loss: 0.5048, Validation Accuracy: 74.92%\n",
      "Epoch  8, Batch 86: \n",
      "Training Loss: 0.3442, Validation Loss: 0.5062, Validation Accuracy: 75.04%\n",
      "Epoch  8, Batch 87: \n",
      "Training Loss: 0.3961, Validation Loss: 0.5171, Validation Accuracy: 74.44%\n",
      "Epoch  8, Batch 88: \n",
      "Training Loss: 0.3758, Validation Loss: 0.5003, Validation Accuracy: 75.16%\n",
      "Epoch  9, Batch 1: \n",
      "Training Loss: 0.3925, Validation Loss: 0.4973, Validation Accuracy: 74.72%\n",
      "Epoch  9, Batch 2: \n",
      "Training Loss: 0.3685, Validation Loss: 0.5047, Validation Accuracy: 74.40%\n",
      "Epoch  9, Batch 3: \n",
      "Training Loss: 0.4307, Validation Loss: 0.5005, Validation Accuracy: 74.24%\n",
      "Epoch  9, Batch 4: \n",
      "Training Loss: 0.3917, Validation Loss: 0.4959, Validation Accuracy: 74.88%\n",
      "Epoch  9, Batch 5: \n",
      "Training Loss: 0.3268, Validation Loss: 0.5007, Validation Accuracy: 75.08%\n",
      "Epoch  9, Batch 6: \n",
      "Training Loss: 0.4396, Validation Loss: 0.5055, Validation Accuracy: 75.44%\n",
      "Epoch  9, Batch 7: \n",
      "Training Loss: 0.4023, Validation Loss: 0.5028, Validation Accuracy: 75.36%\n",
      "Epoch  9, Batch 8: \n",
      "Training Loss: 0.3891, Validation Loss: 0.4989, Validation Accuracy: 75.28%\n",
      "Epoch  9, Batch 9: \n",
      "Training Loss: 0.4323, Validation Loss: 0.5016, Validation Accuracy: 74.44%\n",
      "Epoch  9, Batch 10: \n",
      "Training Loss: 0.4043, Validation Loss: 0.4966, Validation Accuracy: 74.64%\n",
      "Epoch  9, Batch 11: \n",
      "Training Loss: 0.3813, Validation Loss: 0.4931, Validation Accuracy: 75.28%\n",
      "Epoch  9, Batch 12: \n",
      "Training Loss: 0.4472, Validation Loss: 0.4956, Validation Accuracy: 75.04%\n",
      "Epoch  9, Batch 13: \n",
      "Training Loss: 0.4448, Validation Loss: 0.4976, Validation Accuracy: 75.08%\n",
      "Epoch  9, Batch 14: \n",
      "Training Loss: 0.4047, Validation Loss: 0.4942, Validation Accuracy: 75.28%\n",
      "Epoch  9, Batch 15: \n",
      "Training Loss: 0.4032, Validation Loss: 0.4936, Validation Accuracy: 75.44%\n",
      "Epoch  9, Batch 16: \n",
      "Training Loss: 0.4293, Validation Loss: 0.4932, Validation Accuracy: 75.08%\n",
      "Epoch  9, Batch 17: \n",
      "Training Loss: 0.3761, Validation Loss: 0.4931, Validation Accuracy: 74.76%\n",
      "Epoch  9, Batch 18: \n",
      "Training Loss: 0.4464, Validation Loss: 0.4929, Validation Accuracy: 74.96%\n",
      "Epoch  9, Batch 19: \n",
      "Training Loss: 0.3820, Validation Loss: 0.4946, Validation Accuracy: 75.36%\n",
      "Epoch  9, Batch 20: \n",
      "Training Loss: 0.4107, Validation Loss: 0.4980, Validation Accuracy: 75.36%\n",
      "Epoch  9, Batch 21: \n",
      "Training Loss: 0.4038, Validation Loss: 0.4984, Validation Accuracy: 75.32%\n",
      "Epoch  9, Batch 22: \n",
      "Training Loss: 0.4395, Validation Loss: 0.4961, Validation Accuracy: 74.96%\n",
      "Epoch  9, Batch 23: \n",
      "Training Loss: 0.3545, Validation Loss: 0.4956, Validation Accuracy: 75.28%\n",
      "Epoch  9, Batch 24: \n",
      "Training Loss: 0.3472, Validation Loss: 0.4943, Validation Accuracy: 75.56%\n",
      "Epoch  9, Batch 25: \n",
      "Training Loss: 0.3976, Validation Loss: 0.4935, Validation Accuracy: 75.20%\n",
      "Epoch  9, Batch 26: \n",
      "Training Loss: 0.4288, Validation Loss: 0.4938, Validation Accuracy: 75.76%\n",
      "Epoch  9, Batch 27: \n",
      "Training Loss: 0.4167, Validation Loss: 0.4902, Validation Accuracy: 76.16%\n",
      "Epoch  9, Batch 28: \n",
      "Training Loss: 0.3876, Validation Loss: 0.4885, Validation Accuracy: 76.20%\n",
      "Epoch  9, Batch 29: \n",
      "Training Loss: 0.3860, Validation Loss: 0.4905, Validation Accuracy: 76.40%\n",
      "Epoch  9, Batch 30: \n",
      "Training Loss: 0.3849, Validation Loss: 0.4892, Validation Accuracy: 76.28%\n",
      "Epoch  9, Batch 31: \n",
      "Training Loss: 0.3765, Validation Loss: 0.4863, Validation Accuracy: 76.40%\n",
      "Epoch  9, Batch 32: \n",
      "Training Loss: 0.3646, Validation Loss: 0.4874, Validation Accuracy: 76.00%\n",
      "Epoch  9, Batch 33: \n",
      "Training Loss: 0.3897, Validation Loss: 0.4947, Validation Accuracy: 75.68%\n",
      "Epoch  9, Batch 34: \n",
      "Training Loss: 0.4529, Validation Loss: 0.5068, Validation Accuracy: 75.60%\n",
      "Epoch  9, Batch 35: \n",
      "Training Loss: 0.3855, Validation Loss: 0.5043, Validation Accuracy: 75.88%\n",
      "Epoch  9, Batch 36: \n",
      "Training Loss: 0.3769, Validation Loss: 0.4989, Validation Accuracy: 76.08%\n",
      "Epoch  9, Batch 37: \n",
      "Training Loss: 0.3659, Validation Loss: 0.4987, Validation Accuracy: 75.80%\n",
      "Epoch  9, Batch 38: \n",
      "Training Loss: 0.3646, Validation Loss: 0.5137, Validation Accuracy: 74.44%\n",
      "Epoch  9, Batch 39: \n",
      "Training Loss: 0.4189, Validation Loss: 0.5260, Validation Accuracy: 74.24%\n",
      "Epoch  9, Batch 40: \n",
      "Training Loss: 0.3805, Validation Loss: 0.5098, Validation Accuracy: 75.12%\n",
      "Epoch  9, Batch 41: \n",
      "Training Loss: 0.4141, Validation Loss: 0.5086, Validation Accuracy: 75.88%\n",
      "Epoch  9, Batch 42: \n",
      "Training Loss: 0.4080, Validation Loss: 0.5402, Validation Accuracy: 73.92%\n",
      "Epoch  9, Batch 43: \n",
      "Training Loss: 0.3972, Validation Loss: 0.5273, Validation Accuracy: 74.44%\n",
      "Epoch  9, Batch 44: \n",
      "Training Loss: 0.3698, Validation Loss: 0.5011, Validation Accuracy: 76.24%\n",
      "Epoch  9, Batch 45: \n",
      "Training Loss: 0.3726, Validation Loss: 0.4894, Validation Accuracy: 75.44%\n",
      "Epoch  9, Batch 46: \n",
      "Training Loss: 0.3764, Validation Loss: 0.4934, Validation Accuracy: 75.32%\n",
      "Epoch  9, Batch 47: \n",
      "Training Loss: 0.4088, Validation Loss: 0.4985, Validation Accuracy: 75.04%\n",
      "Epoch  9, Batch 48: \n",
      "Training Loss: 0.4013, Validation Loss: 0.4878, Validation Accuracy: 76.24%\n",
      "Epoch  9, Batch 49: \n",
      "Training Loss: 0.3824, Validation Loss: 0.4906, Validation Accuracy: 75.36%\n",
      "Epoch  9, Batch 50: \n",
      "Training Loss: 0.3758, Validation Loss: 0.5126, Validation Accuracy: 74.32%\n",
      "Epoch  9, Batch 51: \n",
      "Training Loss: 0.4277, Validation Loss: 0.5271, Validation Accuracy: 73.96%\n",
      "Epoch  9, Batch 52: \n",
      "Training Loss: 0.3451, Validation Loss: 0.5123, Validation Accuracy: 74.64%\n",
      "Epoch  9, Batch 53: \n",
      "Training Loss: 0.3361, Validation Loss: 0.4940, Validation Accuracy: 75.96%\n",
      "Epoch  9, Batch 54: \n",
      "Training Loss: 0.3522, Validation Loss: 0.4951, Validation Accuracy: 75.72%\n",
      "Epoch  9, Batch 55: \n",
      "Training Loss: 0.4360, Validation Loss: 0.5031, Validation Accuracy: 74.88%\n",
      "Epoch  9, Batch 56: \n",
      "Training Loss: 0.3746, Validation Loss: 0.5007, Validation Accuracy: 75.12%\n",
      "Epoch  9, Batch 57: \n",
      "Training Loss: 0.3804, Validation Loss: 0.4952, Validation Accuracy: 75.72%\n",
      "Epoch  9, Batch 58: \n",
      "Training Loss: 0.3536, Validation Loss: 0.5036, Validation Accuracy: 75.88%\n",
      "Epoch  9, Batch 59: \n",
      "Training Loss: 0.3694, Validation Loss: 0.5067, Validation Accuracy: 75.64%\n",
      "Epoch  9, Batch 60: \n",
      "Training Loss: 0.3820, Validation Loss: 0.5079, Validation Accuracy: 75.52%\n",
      "Epoch  9, Batch 61: \n",
      "Training Loss: 0.3740, Validation Loss: 0.4996, Validation Accuracy: 75.96%\n",
      "Epoch  9, Batch 62: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4172, Validation Loss: 0.4992, Validation Accuracy: 75.56%\n",
      "Epoch  9, Batch 63: \n",
      "Training Loss: 0.3411, Validation Loss: 0.4987, Validation Accuracy: 75.60%\n",
      "Epoch  9, Batch 64: \n",
      "Training Loss: 0.3472, Validation Loss: 0.4984, Validation Accuracy: 75.52%\n",
      "Epoch  9, Batch 65: \n",
      "Training Loss: 0.3709, Validation Loss: 0.5022, Validation Accuracy: 75.24%\n",
      "Epoch  9, Batch 66: \n",
      "Training Loss: 0.3692, Validation Loss: 0.5131, Validation Accuracy: 74.84%\n",
      "Epoch  9, Batch 67: \n",
      "Training Loss: 0.4122, Validation Loss: 0.5066, Validation Accuracy: 75.64%\n",
      "Epoch  9, Batch 68: \n",
      "Training Loss: 0.3516, Validation Loss: 0.4946, Validation Accuracy: 75.52%\n",
      "Epoch  9, Batch 69: \n",
      "Training Loss: 0.3720, Validation Loss: 0.4927, Validation Accuracy: 75.60%\n",
      "Epoch  9, Batch 70: \n",
      "Training Loss: 0.3966, Validation Loss: 0.4922, Validation Accuracy: 75.76%\n",
      "Epoch  9, Batch 71: \n",
      "Training Loss: 0.3883, Validation Loss: 0.4954, Validation Accuracy: 75.72%\n",
      "Epoch  9, Batch 72: \n",
      "Training Loss: 0.3795, Validation Loss: 0.4946, Validation Accuracy: 75.68%\n",
      "Epoch  9, Batch 73: \n",
      "Training Loss: 0.4204, Validation Loss: 0.4884, Validation Accuracy: 75.72%\n",
      "Epoch  9, Batch 74: \n",
      "Training Loss: 0.3224, Validation Loss: 0.4888, Validation Accuracy: 75.80%\n",
      "Epoch  9, Batch 75: \n",
      "Training Loss: 0.3947, Validation Loss: 0.4963, Validation Accuracy: 75.76%\n",
      "Epoch  9, Batch 76: \n",
      "Training Loss: 0.3901, Validation Loss: 0.4975, Validation Accuracy: 75.84%\n",
      "Epoch  9, Batch 77: \n",
      "Training Loss: 0.3516, Validation Loss: 0.4981, Validation Accuracy: 75.68%\n",
      "Epoch  9, Batch 78: \n",
      "Training Loss: 0.3540, Validation Loss: 0.5043, Validation Accuracy: 75.92%\n",
      "Epoch  9, Batch 79: \n",
      "Training Loss: 0.3816, Validation Loss: 0.5018, Validation Accuracy: 75.52%\n",
      "Epoch  9, Batch 80: \n",
      "Training Loss: 0.3355, Validation Loss: 0.5037, Validation Accuracy: 75.52%\n",
      "Epoch  9, Batch 81: \n",
      "Training Loss: 0.3228, Validation Loss: 0.5061, Validation Accuracy: 75.16%\n",
      "Epoch  9, Batch 82: \n",
      "Training Loss: 0.3418, Validation Loss: 0.5064, Validation Accuracy: 75.08%\n",
      "Epoch  9, Batch 83: \n",
      "Training Loss: 0.3659, Validation Loss: 0.5041, Validation Accuracy: 75.08%\n",
      "Epoch  9, Batch 84: \n",
      "Training Loss: 0.4197, Validation Loss: 0.5025, Validation Accuracy: 75.44%\n",
      "Epoch  9, Batch 85: \n",
      "Training Loss: 0.3610, Validation Loss: 0.5087, Validation Accuracy: 75.12%\n",
      "Epoch  9, Batch 86: \n",
      "Training Loss: 0.3312, Validation Loss: 0.5095, Validation Accuracy: 75.20%\n",
      "Epoch  9, Batch 87: \n",
      "Training Loss: 0.3647, Validation Loss: 0.5008, Validation Accuracy: 75.32%\n",
      "Epoch  9, Batch 88: \n",
      "Training Loss: 0.3520, Validation Loss: 0.4971, Validation Accuracy: 75.36%\n",
      "Epoch 10, Batch 1: \n",
      "Training Loss: 0.3730, Validation Loss: 0.4990, Validation Accuracy: 75.44%\n",
      "Epoch 10, Batch 2: \n",
      "Training Loss: 0.3399, Validation Loss: 0.5009, Validation Accuracy: 75.36%\n",
      "Epoch 10, Batch 3: \n",
      "Training Loss: 0.3857, Validation Loss: 0.5123, Validation Accuracy: 75.16%\n",
      "Epoch 10, Batch 4: \n",
      "Training Loss: 0.3759, Validation Loss: 0.5015, Validation Accuracy: 75.44%\n",
      "Epoch 10, Batch 5: \n",
      "Training Loss: 0.2998, Validation Loss: 0.4991, Validation Accuracy: 75.48%\n",
      "Epoch 10, Batch 6: \n",
      "Training Loss: 0.4211, Validation Loss: 0.5119, Validation Accuracy: 74.28%\n",
      "Epoch 10, Batch 7: \n",
      "Training Loss: 0.4021, Validation Loss: 0.5081, Validation Accuracy: 74.44%\n",
      "Epoch 10, Batch 8: \n",
      "Training Loss: 0.3720, Validation Loss: 0.4983, Validation Accuracy: 74.96%\n",
      "Epoch 10, Batch 9: \n",
      "Training Loss: 0.4042, Validation Loss: 0.4866, Validation Accuracy: 75.48%\n",
      "Epoch 10, Batch 10: \n",
      "Training Loss: 0.3964, Validation Loss: 0.4944, Validation Accuracy: 75.80%\n",
      "Epoch 10, Batch 11: \n",
      "Training Loss: 0.3896, Validation Loss: 0.5024, Validation Accuracy: 75.44%\n",
      "Epoch 10, Batch 12: \n",
      "Training Loss: 0.4421, Validation Loss: 0.4938, Validation Accuracy: 75.60%\n",
      "Epoch 10, Batch 13: \n",
      "Training Loss: 0.4172, Validation Loss: 0.4859, Validation Accuracy: 75.52%\n",
      "Epoch 10, Batch 14: \n",
      "Training Loss: 0.3853, Validation Loss: 0.4871, Validation Accuracy: 76.00%\n",
      "Epoch 10, Batch 15: \n",
      "Training Loss: 0.3905, Validation Loss: 0.4912, Validation Accuracy: 75.84%\n",
      "Epoch 10, Batch 16: \n",
      "Training Loss: 0.4103, Validation Loss: 0.4926, Validation Accuracy: 75.56%\n",
      "Epoch 10, Batch 17: \n",
      "Training Loss: 0.3595, Validation Loss: 0.4923, Validation Accuracy: 75.44%\n",
      "Epoch 10, Batch 18: \n",
      "Training Loss: 0.4166, Validation Loss: 0.4925, Validation Accuracy: 75.28%\n",
      "Epoch 10, Batch 19: \n",
      "Training Loss: 0.3542, Validation Loss: 0.4952, Validation Accuracy: 75.12%\n",
      "Epoch 10, Batch 20: \n",
      "Training Loss: 0.3833, Validation Loss: 0.4975, Validation Accuracy: 74.92%\n",
      "Epoch 10, Batch 21: \n",
      "Training Loss: 0.3797, Validation Loss: 0.4965, Validation Accuracy: 74.80%\n",
      "Epoch 10, Batch 22: \n",
      "Training Loss: 0.4035, Validation Loss: 0.4937, Validation Accuracy: 74.92%\n",
      "Epoch 10, Batch 23: \n",
      "Training Loss: 0.3286, Validation Loss: 0.4918, Validation Accuracy: 74.76%\n",
      "Epoch 10, Batch 24: \n",
      "Training Loss: 0.3181, Validation Loss: 0.4916, Validation Accuracy: 74.92%\n",
      "Epoch 10, Batch 25: \n",
      "Training Loss: 0.3847, Validation Loss: 0.4913, Validation Accuracy: 74.92%\n",
      "Epoch 10, Batch 26: \n",
      "Training Loss: 0.4042, Validation Loss: 0.4907, Validation Accuracy: 75.08%\n",
      "Epoch 10, Batch 27: \n",
      "Training Loss: 0.3944, Validation Loss: 0.4901, Validation Accuracy: 75.24%\n",
      "Epoch 10, Batch 28: \n",
      "Training Loss: 0.3689, Validation Loss: 0.4886, Validation Accuracy: 75.72%\n",
      "Epoch 10, Batch 29: \n",
      "Training Loss: 0.3669, Validation Loss: 0.4872, Validation Accuracy: 75.76%\n",
      "Epoch 10, Batch 30: \n",
      "Training Loss: 0.3479, Validation Loss: 0.4878, Validation Accuracy: 76.28%\n",
      "Epoch 10, Batch 31: \n",
      "Training Loss: 0.3439, Validation Loss: 0.4916, Validation Accuracy: 76.04%\n",
      "Epoch 10, Batch 32: \n",
      "Training Loss: 0.3439, Validation Loss: 0.4952, Validation Accuracy: 75.88%\n",
      "Epoch 10, Batch 33: \n",
      "Training Loss: 0.3668, Validation Loss: 0.4962, Validation Accuracy: 75.68%\n",
      "Epoch 10, Batch 34: \n",
      "Training Loss: 0.4439, Validation Loss: 0.4965, Validation Accuracy: 76.08%\n",
      "Epoch 10, Batch 35: \n",
      "Training Loss: 0.3515, Validation Loss: 0.4929, Validation Accuracy: 76.04%\n",
      "Epoch 10, Batch 36: \n",
      "Training Loss: 0.3696, Validation Loss: 0.4916, Validation Accuracy: 76.40%\n",
      "Epoch 10, Batch 37: \n",
      "Training Loss: 0.3495, Validation Loss: 0.4888, Validation Accuracy: 76.92%\n",
      "Epoch 10, Batch 38: \n",
      "Training Loss: 0.3575, Validation Loss: 0.4858, Validation Accuracy: 76.84%\n",
      "Epoch 10, Batch 39: \n",
      "Training Loss: 0.3926, Validation Loss: 0.4893, Validation Accuracy: 75.88%\n",
      "Epoch 10, Batch 40: \n",
      "Training Loss: 0.3757, Validation Loss: 0.4954, Validation Accuracy: 75.64%\n",
      "Epoch 10, Batch 41: \n",
      "Training Loss: 0.4008, Validation Loss: 0.4971, Validation Accuracy: 75.84%\n",
      "Epoch 10, Batch 42: \n",
      "Training Loss: 0.3882, Validation Loss: 0.4968, Validation Accuracy: 76.28%\n",
      "Epoch 10, Batch 43: \n",
      "Training Loss: 0.3833, Validation Loss: 0.5082, Validation Accuracy: 75.36%\n",
      "Epoch 10, Batch 44: \n",
      "Training Loss: 0.3645, Validation Loss: 0.5212, Validation Accuracy: 74.64%\n",
      "Epoch 10, Batch 45: \n",
      "Training Loss: 0.3845, Validation Loss: 0.5094, Validation Accuracy: 75.08%\n",
      "Epoch 10, Batch 46: \n",
      "Training Loss: 0.3543, Validation Loss: 0.4925, Validation Accuracy: 76.28%\n",
      "Epoch 10, Batch 47: \n",
      "Training Loss: 0.3826, Validation Loss: 0.4900, Validation Accuracy: 76.44%\n",
      "Epoch 10, Batch 48: \n",
      "Training Loss: 0.3854, Validation Loss: 0.5002, Validation Accuracy: 74.64%\n",
      "Epoch 10, Batch 49: \n",
      "Training Loss: 0.3715, Validation Loss: 0.4933, Validation Accuracy: 75.40%\n",
      "Epoch 10, Batch 50: \n",
      "Training Loss: 0.3424, Validation Loss: 0.4877, Validation Accuracy: 76.20%\n",
      "Epoch 10, Batch 51: \n",
      "Training Loss: 0.3867, Validation Loss: 0.5076, Validation Accuracy: 75.72%\n",
      "Epoch 10, Batch 52: \n",
      "Training Loss: 0.3217, Validation Loss: 0.5258, Validation Accuracy: 74.40%\n",
      "Epoch 10, Batch 53: \n",
      "Training Loss: 0.3094, Validation Loss: 0.5213, Validation Accuracy: 74.96%\n",
      "Epoch 10, Batch 54: \n",
      "Training Loss: 0.3156, Validation Loss: 0.5058, Validation Accuracy: 76.32%\n",
      "Epoch 10, Batch 55: \n",
      "Training Loss: 0.4046, Validation Loss: 0.5139, Validation Accuracy: 75.72%\n",
      "Epoch 10, Batch 56: \n",
      "Training Loss: 0.3598, Validation Loss: 0.5329, Validation Accuracy: 74.64%\n",
      "Epoch 10, Batch 57: \n",
      "Training Loss: 0.3678, Validation Loss: 0.5067, Validation Accuracy: 75.44%\n",
      "Epoch 10, Batch 58: \n",
      "Training Loss: 0.3197, Validation Loss: 0.4984, Validation Accuracy: 76.00%\n",
      "Epoch 10, Batch 59: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3428, Validation Loss: 0.4992, Validation Accuracy: 76.44%\n",
      "Epoch 10, Batch 60: \n",
      "Training Loss: 0.3650, Validation Loss: 0.5052, Validation Accuracy: 76.12%\n",
      "Epoch 10, Batch 61: \n",
      "Training Loss: 0.3558, Validation Loss: 0.5005, Validation Accuracy: 76.36%\n",
      "Epoch 10, Batch 62: \n",
      "Training Loss: 0.3793, Validation Loss: 0.5005, Validation Accuracy: 76.12%\n",
      "Epoch 10, Batch 63: \n",
      "Training Loss: 0.3280, Validation Loss: 0.4978, Validation Accuracy: 76.32%\n",
      "Epoch 10, Batch 64: \n",
      "Training Loss: 0.3354, Validation Loss: 0.4950, Validation Accuracy: 75.48%\n",
      "Epoch 10, Batch 65: \n",
      "Training Loss: 0.3629, Validation Loss: 0.4963, Validation Accuracy: 75.56%\n",
      "Epoch 10, Batch 66: \n",
      "Training Loss: 0.3556, Validation Loss: 0.5024, Validation Accuracy: 75.64%\n",
      "Epoch 10, Batch 67: \n",
      "Training Loss: 0.4059, Validation Loss: 0.5037, Validation Accuracy: 75.36%\n",
      "Epoch 10, Batch 68: \n",
      "Training Loss: 0.3332, Validation Loss: 0.5019, Validation Accuracy: 75.52%\n",
      "Epoch 10, Batch 69: \n",
      "Training Loss: 0.3587, Validation Loss: 0.4958, Validation Accuracy: 75.44%\n",
      "Epoch 10, Batch 70: \n",
      "Training Loss: 0.3771, Validation Loss: 0.4951, Validation Accuracy: 75.52%\n",
      "Epoch 10, Batch 71: \n",
      "Training Loss: 0.3647, Validation Loss: 0.5044, Validation Accuracy: 75.88%\n",
      "Epoch 10, Batch 72: \n",
      "Training Loss: 0.3545, Validation Loss: 0.5240, Validation Accuracy: 75.72%\n",
      "Epoch 10, Batch 73: \n",
      "Training Loss: 0.4080, Validation Loss: 0.4988, Validation Accuracy: 75.52%\n",
      "Epoch 10, Batch 74: \n",
      "Training Loss: 0.3015, Validation Loss: 0.4933, Validation Accuracy: 76.16%\n",
      "Epoch 10, Batch 75: \n",
      "Training Loss: 0.3870, Validation Loss: 0.5054, Validation Accuracy: 75.76%\n",
      "Epoch 10, Batch 76: \n",
      "Training Loss: 0.3767, Validation Loss: 0.5081, Validation Accuracy: 75.68%\n",
      "Epoch 10, Batch 77: \n",
      "Training Loss: 0.3431, Validation Loss: 0.5002, Validation Accuracy: 75.48%\n",
      "Epoch 10, Batch 78: \n",
      "Training Loss: 0.3466, Validation Loss: 0.4996, Validation Accuracy: 75.60%\n",
      "Epoch 10, Batch 79: \n",
      "Training Loss: 0.3789, Validation Loss: 0.5028, Validation Accuracy: 74.28%\n",
      "Epoch 10, Batch 80: \n",
      "Training Loss: 0.3384, Validation Loss: 0.5048, Validation Accuracy: 74.00%\n",
      "Epoch 10, Batch 81: \n",
      "Training Loss: 0.3250, Validation Loss: 0.5041, Validation Accuracy: 74.48%\n",
      "Epoch 10, Batch 82: \n",
      "Training Loss: 0.3164, Validation Loss: 0.5061, Validation Accuracy: 75.40%\n",
      "Epoch 10, Batch 83: \n",
      "Training Loss: 0.3429, Validation Loss: 0.5126, Validation Accuracy: 75.24%\n",
      "Epoch 10, Batch 84: \n",
      "Training Loss: 0.3958, Validation Loss: 0.5104, Validation Accuracy: 75.44%\n",
      "Epoch 10, Batch 85: \n",
      "Training Loss: 0.3360, Validation Loss: 0.5053, Validation Accuracy: 75.44%\n",
      "Epoch 10, Batch 86: \n",
      "Training Loss: 0.2988, Validation Loss: 0.5020, Validation Accuracy: 75.32%\n",
      "Epoch 10, Batch 87: \n",
      "Training Loss: 0.3402, Validation Loss: 0.5019, Validation Accuracy: 75.56%\n",
      "Epoch 10, Batch 88: \n",
      "Training Loss: 0.3200, Validation Loss: 0.4971, Validation Accuracy: 75.80%\n",
      "Epoch 11, Batch 1: \n",
      "Training Loss: 0.3571, Validation Loss: 0.4930, Validation Accuracy: 75.72%\n",
      "Epoch 11, Batch 2: \n",
      "Training Loss: 0.3199, Validation Loss: 0.4931, Validation Accuracy: 75.56%\n",
      "Epoch 11, Batch 3: \n",
      "Training Loss: 0.3708, Validation Loss: 0.4923, Validation Accuracy: 75.56%\n",
      "Epoch 11, Batch 4: \n",
      "Training Loss: 0.3419, Validation Loss: 0.4926, Validation Accuracy: 76.00%\n",
      "Epoch 11, Batch 5: \n",
      "Training Loss: 0.2909, Validation Loss: 0.4933, Validation Accuracy: 75.84%\n",
      "Epoch 11, Batch 6: \n",
      "Training Loss: 0.3883, Validation Loss: 0.4939, Validation Accuracy: 75.40%\n",
      "Epoch 11, Batch 7: \n",
      "Training Loss: 0.3740, Validation Loss: 0.4954, Validation Accuracy: 75.76%\n",
      "Epoch 11, Batch 8: \n",
      "Training Loss: 0.3533, Validation Loss: 0.4971, Validation Accuracy: 75.56%\n",
      "Epoch 11, Batch 9: \n",
      "Training Loss: 0.3781, Validation Loss: 0.4971, Validation Accuracy: 75.20%\n",
      "Epoch 11, Batch 10: \n",
      "Training Loss: 0.3618, Validation Loss: 0.4950, Validation Accuracy: 75.52%\n",
      "Epoch 11, Batch 11: \n",
      "Training Loss: 0.3538, Validation Loss: 0.4968, Validation Accuracy: 76.40%\n",
      "Epoch 11, Batch 12: \n",
      "Training Loss: 0.4229, Validation Loss: 0.5012, Validation Accuracy: 75.64%\n",
      "Epoch 11, Batch 13: \n",
      "Training Loss: 0.3998, Validation Loss: 0.4915, Validation Accuracy: 75.80%\n",
      "Epoch 11, Batch 14: \n",
      "Training Loss: 0.3565, Validation Loss: 0.4859, Validation Accuracy: 76.00%\n",
      "Epoch 11, Batch 15: \n",
      "Training Loss: 0.3734, Validation Loss: 0.4879, Validation Accuracy: 76.20%\n",
      "Epoch 11, Batch 16: \n",
      "Training Loss: 0.3985, Validation Loss: 0.4933, Validation Accuracy: 75.56%\n",
      "Epoch 11, Batch 17: \n",
      "Training Loss: 0.3544, Validation Loss: 0.4929, Validation Accuracy: 75.80%\n",
      "Epoch 11, Batch 18: \n",
      "Training Loss: 0.3923, Validation Loss: 0.4877, Validation Accuracy: 76.00%\n",
      "Epoch 11, Batch 19: \n",
      "Training Loss: 0.3297, Validation Loss: 0.4867, Validation Accuracy: 76.04%\n",
      "Epoch 11, Batch 20: \n",
      "Training Loss: 0.3724, Validation Loss: 0.4903, Validation Accuracy: 75.72%\n",
      "Epoch 11, Batch 21: \n",
      "Training Loss: 0.3475, Validation Loss: 0.4925, Validation Accuracy: 75.68%\n",
      "Epoch 11, Batch 22: \n",
      "Training Loss: 0.3885, Validation Loss: 0.4921, Validation Accuracy: 75.32%\n",
      "Epoch 11, Batch 23: \n",
      "Training Loss: 0.3051, Validation Loss: 0.4935, Validation Accuracy: 75.28%\n",
      "Epoch 11, Batch 24: \n",
      "Training Loss: 0.3005, Validation Loss: 0.4981, Validation Accuracy: 75.24%\n",
      "Epoch 11, Batch 25: \n",
      "Training Loss: 0.3673, Validation Loss: 0.5055, Validation Accuracy: 75.36%\n",
      "Epoch 11, Batch 26: \n",
      "Training Loss: 0.3952, Validation Loss: 0.5024, Validation Accuracy: 74.88%\n",
      "Epoch 11, Batch 27: \n",
      "Training Loss: 0.3608, Validation Loss: 0.4905, Validation Accuracy: 75.40%\n",
      "Epoch 11, Batch 28: \n",
      "Training Loss: 0.3543, Validation Loss: 0.4995, Validation Accuracy: 75.72%\n",
      "Epoch 11, Batch 29: \n",
      "Training Loss: 0.3607, Validation Loss: 0.5092, Validation Accuracy: 75.60%\n",
      "Epoch 11, Batch 30: \n",
      "Training Loss: 0.3402, Validation Loss: 0.4949, Validation Accuracy: 75.76%\n",
      "Epoch 11, Batch 31: \n",
      "Training Loss: 0.3259, Validation Loss: 0.4946, Validation Accuracy: 75.80%\n",
      "Epoch 11, Batch 32: \n",
      "Training Loss: 0.3307, Validation Loss: 0.5021, Validation Accuracy: 75.12%\n",
      "Epoch 11, Batch 33: \n",
      "Training Loss: 0.3635, Validation Loss: 0.5039, Validation Accuracy: 75.20%\n",
      "Epoch 11, Batch 34: \n",
      "Training Loss: 0.4128, Validation Loss: 0.5033, Validation Accuracy: 75.16%\n",
      "Epoch 11, Batch 35: \n",
      "Training Loss: 0.3504, Validation Loss: 0.4944, Validation Accuracy: 75.88%\n",
      "Epoch 11, Batch 36: \n",
      "Training Loss: 0.3564, Validation Loss: 0.4908, Validation Accuracy: 76.16%\n",
      "Epoch 11, Batch 37: \n",
      "Training Loss: 0.3283, Validation Loss: 0.4888, Validation Accuracy: 76.32%\n",
      "Epoch 11, Batch 38: \n",
      "Training Loss: 0.3460, Validation Loss: 0.4903, Validation Accuracy: 76.84%\n",
      "Epoch 11, Batch 39: \n",
      "Training Loss: 0.3816, Validation Loss: 0.4944, Validation Accuracy: 76.24%\n",
      "Epoch 11, Batch 40: \n",
      "Training Loss: 0.3446, Validation Loss: 0.5015, Validation Accuracy: 75.92%\n",
      "Epoch 11, Batch 41: \n",
      "Training Loss: 0.3766, Validation Loss: 0.5027, Validation Accuracy: 75.76%\n",
      "Epoch 11, Batch 42: \n",
      "Training Loss: 0.3641, Validation Loss: 0.5014, Validation Accuracy: 76.64%\n",
      "Epoch 11, Batch 43: \n",
      "Training Loss: 0.3503, Validation Loss: 0.5168, Validation Accuracy: 75.84%\n",
      "Epoch 11, Batch 44: \n",
      "Training Loss: 0.3461, Validation Loss: 0.5268, Validation Accuracy: 74.76%\n",
      "Epoch 11, Batch 45: \n",
      "Training Loss: 0.3649, Validation Loss: 0.5036, Validation Accuracy: 76.12%\n",
      "Epoch 11, Batch 46: \n",
      "Training Loss: 0.3350, Validation Loss: 0.4845, Validation Accuracy: 76.60%\n",
      "Epoch 11, Batch 47: \n",
      "Training Loss: 0.3580, Validation Loss: 0.4876, Validation Accuracy: 76.32%\n",
      "Epoch 11, Batch 48: \n",
      "Training Loss: 0.3645, Validation Loss: 0.4947, Validation Accuracy: 75.56%\n",
      "Epoch 11, Batch 49: \n",
      "Training Loss: 0.3597, Validation Loss: 0.4938, Validation Accuracy: 75.40%\n",
      "Epoch 11, Batch 50: \n",
      "Training Loss: 0.3522, Validation Loss: 0.4872, Validation Accuracy: 75.76%\n",
      "Epoch 11, Batch 51: \n",
      "Training Loss: 0.3666, Validation Loss: 0.4922, Validation Accuracy: 75.84%\n",
      "Epoch 11, Batch 52: \n",
      "Training Loss: 0.3122, Validation Loss: 0.5047, Validation Accuracy: 75.04%\n",
      "Epoch 11, Batch 53: \n",
      "Training Loss: 0.3199, Validation Loss: 0.5140, Validation Accuracy: 74.56%\n",
      "Epoch 11, Batch 54: \n",
      "Training Loss: 0.3146, Validation Loss: 0.5078, Validation Accuracy: 76.08%\n",
      "Epoch 11, Batch 55: \n",
      "Training Loss: 0.3786, Validation Loss: 0.5034, Validation Accuracy: 75.72%\n",
      "Epoch 11, Batch 56: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3447, Validation Loss: 0.5068, Validation Accuracy: 75.48%\n",
      "Epoch 11, Batch 57: \n",
      "Training Loss: 0.3627, Validation Loss: 0.5187, Validation Accuracy: 75.20%\n",
      "Epoch 11, Batch 58: \n",
      "Training Loss: 0.3081, Validation Loss: 0.5241, Validation Accuracy: 74.56%\n",
      "Epoch 11, Batch 59: \n",
      "Training Loss: 0.3284, Validation Loss: 0.5108, Validation Accuracy: 75.68%\n",
      "Epoch 11, Batch 60: \n",
      "Training Loss: 0.3359, Validation Loss: 0.5096, Validation Accuracy: 76.12%\n",
      "Epoch 11, Batch 61: \n",
      "Training Loss: 0.3561, Validation Loss: 0.5168, Validation Accuracy: 75.48%\n",
      "Epoch 11, Batch 62: \n",
      "Training Loss: 0.3671, Validation Loss: 0.5196, Validation Accuracy: 75.08%\n",
      "Epoch 11, Batch 63: \n",
      "Training Loss: 0.3207, Validation Loss: 0.5036, Validation Accuracy: 75.56%\n",
      "Epoch 11, Batch 64: \n",
      "Training Loss: 0.3164, Validation Loss: 0.4897, Validation Accuracy: 76.28%\n",
      "Epoch 11, Batch 65: \n",
      "Training Loss: 0.3532, Validation Loss: 0.4868, Validation Accuracy: 76.36%\n",
      "Epoch 11, Batch 66: \n",
      "Training Loss: 0.3520, Validation Loss: 0.4862, Validation Accuracy: 76.28%\n",
      "Epoch 11, Batch 67: \n",
      "Training Loss: 0.3915, Validation Loss: 0.4856, Validation Accuracy: 76.28%\n",
      "Epoch 11, Batch 68: \n",
      "Training Loss: 0.3243, Validation Loss: 0.4863, Validation Accuracy: 76.28%\n",
      "Epoch 11, Batch 69: \n",
      "Training Loss: 0.3425, Validation Loss: 0.4858, Validation Accuracy: 76.40%\n",
      "Epoch 11, Batch 70: \n",
      "Training Loss: 0.3597, Validation Loss: 0.4853, Validation Accuracy: 76.28%\n",
      "Epoch 11, Batch 71: \n",
      "Training Loss: 0.3580, Validation Loss: 0.4874, Validation Accuracy: 76.08%\n",
      "Epoch 11, Batch 72: \n",
      "Training Loss: 0.3612, Validation Loss: 0.4959, Validation Accuracy: 75.68%\n",
      "Epoch 11, Batch 73: \n",
      "Training Loss: 0.3964, Validation Loss: 0.5062, Validation Accuracy: 75.88%\n",
      "Epoch 11, Batch 74: \n",
      "Training Loss: 0.2939, Validation Loss: 0.5048, Validation Accuracy: 75.72%\n",
      "Epoch 11, Batch 75: \n",
      "Training Loss: 0.3618, Validation Loss: 0.4985, Validation Accuracy: 75.88%\n",
      "Epoch 11, Batch 76: \n",
      "Training Loss: 0.3542, Validation Loss: 0.5113, Validation Accuracy: 75.88%\n",
      "Epoch 11, Batch 77: \n",
      "Training Loss: 0.3192, Validation Loss: 0.5375, Validation Accuracy: 75.80%\n",
      "Epoch 11, Batch 78: \n",
      "Training Loss: 0.3104, Validation Loss: 0.5512, Validation Accuracy: 75.12%\n",
      "Epoch 11, Batch 79: \n",
      "Training Loss: 0.3584, Validation Loss: 0.5247, Validation Accuracy: 76.12%\n",
      "Epoch 11, Batch 80: \n",
      "Training Loss: 0.3178, Validation Loss: 0.5227, Validation Accuracy: 75.56%\n",
      "Epoch 11, Batch 81: \n",
      "Training Loss: 0.3236, Validation Loss: 0.5307, Validation Accuracy: 74.84%\n",
      "Epoch 11, Batch 82: \n",
      "Training Loss: 0.3112, Validation Loss: 0.5183, Validation Accuracy: 75.16%\n",
      "Epoch 11, Batch 83: \n",
      "Training Loss: 0.3356, Validation Loss: 0.5037, Validation Accuracy: 75.76%\n",
      "Epoch 11, Batch 84: \n",
      "Training Loss: 0.3898, Validation Loss: 0.5061, Validation Accuracy: 75.44%\n",
      "Epoch 11, Batch 85: \n",
      "Training Loss: 0.3564, Validation Loss: 0.5171, Validation Accuracy: 74.84%\n",
      "Epoch 11, Batch 86: \n",
      "Training Loss: 0.3259, Validation Loss: 0.5235, Validation Accuracy: 74.04%\n",
      "Epoch 11, Batch 87: \n",
      "Training Loss: 0.3501, Validation Loss: 0.5194, Validation Accuracy: 74.68%\n",
      "Epoch 11, Batch 88: \n",
      "Training Loss: 0.3290, Validation Loss: 0.5068, Validation Accuracy: 75.24%\n",
      "Epoch 12, Batch 1: \n",
      "Training Loss: 0.3405, Validation Loss: 0.5059, Validation Accuracy: 75.36%\n",
      "Epoch 12, Batch 2: \n",
      "Training Loss: 0.3353, Validation Loss: 0.5106, Validation Accuracy: 75.48%\n",
      "Epoch 12, Batch 3: \n",
      "Training Loss: 0.3550, Validation Loss: 0.5180, Validation Accuracy: 75.40%\n",
      "Epoch 12, Batch 4: \n",
      "Training Loss: 0.3296, Validation Loss: 0.5124, Validation Accuracy: 75.28%\n",
      "Epoch 12, Batch 5: \n",
      "Training Loss: 0.2701, Validation Loss: 0.5126, Validation Accuracy: 75.60%\n",
      "Epoch 12, Batch 6: \n",
      "Training Loss: 0.3744, Validation Loss: 0.5255, Validation Accuracy: 75.24%\n",
      "Epoch 12, Batch 7: \n",
      "Training Loss: 0.3659, Validation Loss: 0.5229, Validation Accuracy: 75.48%\n",
      "Epoch 12, Batch 8: \n",
      "Training Loss: 0.3422, Validation Loss: 0.5189, Validation Accuracy: 75.28%\n",
      "Epoch 12, Batch 9: \n",
      "Training Loss: 0.3677, Validation Loss: 0.5046, Validation Accuracy: 75.96%\n",
      "Epoch 12, Batch 10: \n",
      "Training Loss: 0.3500, Validation Loss: 0.4953, Validation Accuracy: 75.88%\n",
      "Epoch 12, Batch 11: \n",
      "Training Loss: 0.3510, Validation Loss: 0.4967, Validation Accuracy: 75.64%\n",
      "Epoch 12, Batch 12: \n",
      "Training Loss: 0.3985, Validation Loss: 0.4975, Validation Accuracy: 75.72%\n",
      "Epoch 12, Batch 13: \n",
      "Training Loss: 0.3947, Validation Loss: 0.4992, Validation Accuracy: 75.72%\n",
      "Epoch 12, Batch 14: \n",
      "Training Loss: 0.3566, Validation Loss: 0.4908, Validation Accuracy: 75.88%\n",
      "Epoch 12, Batch 15: \n",
      "Training Loss: 0.3479, Validation Loss: 0.4868, Validation Accuracy: 75.96%\n",
      "Epoch 12, Batch 16: \n",
      "Training Loss: 0.3823, Validation Loss: 0.4871, Validation Accuracy: 76.08%\n",
      "Epoch 12, Batch 17: \n",
      "Training Loss: 0.3366, Validation Loss: 0.4891, Validation Accuracy: 76.04%\n",
      "Epoch 12, Batch 18: \n",
      "Training Loss: 0.3796, Validation Loss: 0.4888, Validation Accuracy: 76.32%\n",
      "Epoch 12, Batch 19: \n",
      "Training Loss: 0.3239, Validation Loss: 0.4871, Validation Accuracy: 76.48%\n",
      "Epoch 12, Batch 20: \n",
      "Training Loss: 0.3564, Validation Loss: 0.4859, Validation Accuracy: 76.08%\n",
      "Epoch 12, Batch 21: \n",
      "Training Loss: 0.3300, Validation Loss: 0.4874, Validation Accuracy: 76.24%\n",
      "Epoch 12, Batch 22: \n",
      "Training Loss: 0.3546, Validation Loss: 0.4902, Validation Accuracy: 76.24%\n",
      "Epoch 12, Batch 23: \n",
      "Training Loss: 0.2878, Validation Loss: 0.4895, Validation Accuracy: 76.20%\n",
      "Epoch 12, Batch 24: \n",
      "Training Loss: 0.2656, Validation Loss: 0.4944, Validation Accuracy: 76.16%\n",
      "Epoch 12, Batch 25: \n",
      "Training Loss: 0.3406, Validation Loss: 0.5139, Validation Accuracy: 75.20%\n",
      "Epoch 12, Batch 26: \n",
      "Training Loss: 0.3809, Validation Loss: 0.5127, Validation Accuracy: 75.52%\n",
      "Epoch 12, Batch 27: \n",
      "Training Loss: 0.3450, Validation Loss: 0.4953, Validation Accuracy: 76.12%\n",
      "Epoch 12, Batch 28: \n",
      "Training Loss: 0.3280, Validation Loss: 0.4998, Validation Accuracy: 76.04%\n",
      "Epoch 12, Batch 29: \n",
      "Training Loss: 0.3399, Validation Loss: 0.5107, Validation Accuracy: 75.92%\n",
      "Epoch 12, Batch 30: \n",
      "Training Loss: 0.3181, Validation Loss: 0.5024, Validation Accuracy: 75.80%\n",
      "Epoch 12, Batch 31: \n",
      "Training Loss: 0.3081, Validation Loss: 0.4905, Validation Accuracy: 76.32%\n",
      "Epoch 12, Batch 32: \n",
      "Training Loss: 0.3081, Validation Loss: 0.4999, Validation Accuracy: 76.44%\n",
      "Epoch 12, Batch 33: \n",
      "Training Loss: 0.3465, Validation Loss: 0.5139, Validation Accuracy: 76.04%\n",
      "Epoch 12, Batch 34: \n",
      "Training Loss: 0.3922, Validation Loss: 0.5163, Validation Accuracy: 75.96%\n",
      "Epoch 12, Batch 35: \n",
      "Training Loss: 0.3309, Validation Loss: 0.5005, Validation Accuracy: 76.36%\n",
      "Epoch 12, Batch 36: \n",
      "Training Loss: 0.3415, Validation Loss: 0.4915, Validation Accuracy: 76.96%\n",
      "Epoch 12, Batch 37: \n",
      "Training Loss: 0.3179, Validation Loss: 0.4872, Validation Accuracy: 76.52%\n",
      "Epoch 12, Batch 38: \n",
      "Training Loss: 0.3284, Validation Loss: 0.4895, Validation Accuracy: 77.08%\n",
      "Epoch 12, Batch 39: \n",
      "Training Loss: 0.3653, Validation Loss: 0.4937, Validation Accuracy: 76.76%\n",
      "Epoch 12, Batch 40: \n",
      "Training Loss: 0.3310, Validation Loss: 0.4945, Validation Accuracy: 76.84%\n",
      "Epoch 12, Batch 41: \n",
      "Training Loss: 0.3481, Validation Loss: 0.4940, Validation Accuracy: 76.84%\n",
      "Epoch 12, Batch 42: \n",
      "Training Loss: 0.3352, Validation Loss: 0.4958, Validation Accuracy: 76.88%\n",
      "Epoch 12, Batch 43: \n",
      "Training Loss: 0.3136, Validation Loss: 0.5073, Validation Accuracy: 76.24%\n",
      "Epoch 12, Batch 44: \n",
      "Training Loss: 0.3072, Validation Loss: 0.5151, Validation Accuracy: 76.08%\n",
      "Epoch 12, Batch 45: \n",
      "Training Loss: 0.3290, Validation Loss: 0.5036, Validation Accuracy: 76.32%\n",
      "Epoch 12, Batch 46: \n",
      "Training Loss: 0.3162, Validation Loss: 0.4932, Validation Accuracy: 76.44%\n",
      "Epoch 12, Batch 47: \n",
      "Training Loss: 0.3338, Validation Loss: 0.4864, Validation Accuracy: 76.52%\n",
      "Epoch 12, Batch 48: \n",
      "Training Loss: 0.3193, Validation Loss: 0.4883, Validation Accuracy: 76.52%\n",
      "Epoch 12, Batch 49: \n",
      "Training Loss: 0.3129, Validation Loss: 0.4925, Validation Accuracy: 76.20%\n",
      "Epoch 12, Batch 50: \n",
      "Training Loss: 0.3192, Validation Loss: 0.4953, Validation Accuracy: 75.88%\n",
      "Epoch 12, Batch 51: \n",
      "Training Loss: 0.3579, Validation Loss: 0.5039, Validation Accuracy: 76.08%\n",
      "Epoch 12, Batch 52: \n",
      "Training Loss: 0.2782, Validation Loss: 0.5092, Validation Accuracy: 75.68%\n",
      "Epoch 12, Batch 53: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.2822, Validation Loss: 0.5096, Validation Accuracy: 76.36%\n",
      "Epoch 12, Batch 54: \n",
      "Training Loss: 0.2844, Validation Loss: 0.5108, Validation Accuracy: 76.16%\n",
      "Epoch 12, Batch 55: \n",
      "Training Loss: 0.3710, Validation Loss: 0.5037, Validation Accuracy: 76.40%\n",
      "Epoch 12, Batch 56: \n",
      "Training Loss: 0.3048, Validation Loss: 0.4955, Validation Accuracy: 76.64%\n",
      "Epoch 12, Batch 57: \n",
      "Training Loss: 0.3136, Validation Loss: 0.5010, Validation Accuracy: 76.12%\n",
      "Epoch 12, Batch 58: \n",
      "Training Loss: 0.2818, Validation Loss: 0.5109, Validation Accuracy: 75.88%\n",
      "Epoch 12, Batch 59: \n",
      "Training Loss: 0.3043, Validation Loss: 0.4976, Validation Accuracy: 76.48%\n",
      "Epoch 12, Batch 60: \n",
      "Training Loss: 0.3208, Validation Loss: 0.4973, Validation Accuracy: 76.80%\n",
      "Epoch 12, Batch 61: \n",
      "Training Loss: 0.3457, Validation Loss: 0.5286, Validation Accuracy: 75.68%\n",
      "Epoch 12, Batch 62: \n",
      "Training Loss: 0.3619, Validation Loss: 0.5558, Validation Accuracy: 74.32%\n",
      "Epoch 12, Batch 63: \n",
      "Training Loss: 0.3025, Validation Loss: 0.5227, Validation Accuracy: 75.72%\n",
      "Epoch 12, Batch 64: \n",
      "Training Loss: 0.2979, Validation Loss: 0.4914, Validation Accuracy: 76.44%\n",
      "Epoch 12, Batch 65: \n",
      "Training Loss: 0.3260, Validation Loss: 0.4904, Validation Accuracy: 76.64%\n",
      "Epoch 12, Batch 66: \n",
      "Training Loss: 0.3335, Validation Loss: 0.4918, Validation Accuracy: 76.72%\n",
      "Epoch 12, Batch 67: \n",
      "Training Loss: 0.3558, Validation Loss: 0.4907, Validation Accuracy: 76.84%\n",
      "Epoch 12, Batch 68: \n",
      "Training Loss: 0.2974, Validation Loss: 0.4919, Validation Accuracy: 76.12%\n",
      "Epoch 12, Batch 69: \n",
      "Training Loss: 0.3244, Validation Loss: 0.4935, Validation Accuracy: 76.16%\n",
      "Epoch 12, Batch 70: \n",
      "Training Loss: 0.3515, Validation Loss: 0.4931, Validation Accuracy: 75.88%\n",
      "Epoch 12, Batch 71: \n",
      "Training Loss: 0.3472, Validation Loss: 0.4924, Validation Accuracy: 76.04%\n",
      "Epoch 12, Batch 72: \n",
      "Training Loss: 0.3360, Validation Loss: 0.5052, Validation Accuracy: 75.88%\n",
      "Epoch 12, Batch 73: \n",
      "Training Loss: 0.3825, Validation Loss: 0.5139, Validation Accuracy: 75.32%\n",
      "Epoch 12, Batch 74: \n",
      "Training Loss: 0.2981, Validation Loss: 0.5046, Validation Accuracy: 75.48%\n",
      "Epoch 12, Batch 75: \n",
      "Training Loss: 0.3473, Validation Loss: 0.4917, Validation Accuracy: 76.28%\n",
      "Epoch 12, Batch 76: \n",
      "Training Loss: 0.3441, Validation Loss: 0.4845, Validation Accuracy: 76.56%\n",
      "Epoch 12, Batch 77: \n",
      "Training Loss: 0.3156, Validation Loss: 0.4935, Validation Accuracy: 76.64%\n",
      "Epoch 12, Batch 78: \n",
      "Training Loss: 0.3098, Validation Loss: 0.5137, Validation Accuracy: 75.00%\n",
      "Epoch 12, Batch 79: \n",
      "Training Loss: 0.3545, Validation Loss: 0.5136, Validation Accuracy: 75.36%\n",
      "Epoch 12, Batch 80: \n",
      "Training Loss: 0.3002, Validation Loss: 0.5031, Validation Accuracy: 76.08%\n",
      "Epoch 12, Batch 81: \n",
      "Training Loss: 0.3000, Validation Loss: 0.4965, Validation Accuracy: 76.56%\n",
      "Epoch 12, Batch 82: \n",
      "Training Loss: 0.2809, Validation Loss: 0.5087, Validation Accuracy: 76.12%\n",
      "Epoch 12, Batch 83: \n",
      "Training Loss: 0.3214, Validation Loss: 0.5177, Validation Accuracy: 75.56%\n",
      "Epoch 12, Batch 84: \n",
      "Training Loss: 0.3726, Validation Loss: 0.5107, Validation Accuracy: 75.92%\n",
      "Epoch 12, Batch 85: \n",
      "Training Loss: 0.2954, Validation Loss: 0.5109, Validation Accuracy: 75.56%\n",
      "Epoch 12, Batch 86: \n",
      "Training Loss: 0.2717, Validation Loss: 0.5178, Validation Accuracy: 76.12%\n",
      "Epoch 12, Batch 87: \n",
      "Training Loss: 0.3119, Validation Loss: 0.5169, Validation Accuracy: 75.92%\n",
      "Epoch 12, Batch 88: \n",
      "Training Loss: 0.2806, Validation Loss: 0.5075, Validation Accuracy: 75.92%\n"
     ]
    }
   ],
   "source": [
    "save_model_path = './dog_vs_cat'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    #Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        for batch_start in range(0, train_feature.shape[0], batch_size):\n",
    "            batch_end = min(batch_start + batch_size, feature.shape[0])\n",
    "            feature_batch = train_feature[batch_start: batch_end]\n",
    "            label_batch = train_label[batch_start: batch_end]\n",
    "\n",
    "            sess.run(optimizer, feed_dict={\n",
    "                    x: feature_batch,\n",
    "                    y: label_batch,\n",
    "                    keep_prob: keep_probability\n",
    "                })\n",
    "            print('Epoch {:>2}, Batch {}: '.format(epoch + 1, int(batch_start/batch_size + 1)))\n",
    "            loss = sess.run(cost, feed_dict={\n",
    "                    x: feature_batch,\n",
    "                    y: label_batch,\n",
    "                    keep_prob: 1.\n",
    "                })\n",
    "            \n",
    "            valid_loss = sess.run(cost, feed_dict={\n",
    "                    x: val_feature,\n",
    "                    y: val_label,\n",
    "                    keep_prob: 1.\n",
    "                })\n",
    "            \n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                    x: val_feature,\n",
    "                    y: val_label,\n",
    "                    keep_prob: 1.\n",
    "                })\n",
    "            print('Training Loss: {:>3.4f}, Validation Loss: {:>3.4f}, Validation Accuracy: {:.2f}%'.format(loss, valid_loss, valid_acc*100))\n",
    "    \n",
    "    # Save model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
